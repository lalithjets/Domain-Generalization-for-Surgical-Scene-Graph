{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "configurations of the network\n",
    "    \n",
    "    readout: G_ER_L_S = [1024+300+16+300+1024,  1024, 117]\n",
    "\n",
    "    node_func: G_N_L_S = [1024+1024, 1024]\n",
    "    node_lang_func: G_N_L_S2 = [300+300+300]\n",
    "    \n",
    "    edge_func : G_E_L_S = [1024*2+16, 1024]\n",
    "    edge_lang_func: [300*2, 1024]\n",
    "    \n",
    "    attn: [1024, 1]\n",
    "    attn_lang: [1024, 1]\n",
    "'''\n",
    "\n",
    "class CONFIGURATION(object):\n",
    "    '''\n",
    "    Configuration arguments: feature type, layer, bias, batch normalization, dropout, multi-attn\n",
    "    \n",
    "    readout           : fc_size, activation, bias, bn, droupout\n",
    "    gnn_node          : fc_size, activation, bias, bn, droupout\n",
    "    gnn_node_for_lang : fc_size, activation, bias, bn, droupout\n",
    "    gnn_edge          : fc_size, activation, bias, bn, droupout\n",
    "    gnn_edge_for_lang : fc_size, activation, bias, bn, droupout\n",
    "    gnn_attn          : fc_size, activation, bias, bn, droupout\n",
    "    gnn_attn_for_lang : fc_size, activation, bias, bn, droupout\n",
    "    '''\n",
    "    def __init__(self, layer=1, bias=True, bn=False, dropout=0.2, multi_attn=False):\n",
    "        \n",
    "        # if multi_attn:\n",
    "        if True:\n",
    "            if layer==1:\n",
    "                feature_size = 512\n",
    "                # readout\n",
    "                self.G_ER_L_S = [feature_size+300+16+300+feature_size, feature_size, 13]\n",
    "                self.G_ER_A   = ['ReLU', 'Identity']\n",
    "                self.G_ER_B   = bias    #true\n",
    "                self.G_ER_BN  = bn      #false\n",
    "                self.G_ER_D   = dropout #0.3\n",
    "                # self.G_ER_GRU = feature_size\n",
    "\n",
    "                # # gnn node function\n",
    "                self.G_N_L_S = [feature_size+feature_size, feature_size]\n",
    "                self.G_N_A   = ['ReLU']\n",
    "                self.G_N_B   = bias #true\n",
    "                self.G_N_BN  = bn      #false\n",
    "                self.G_N_D   = dropout #0.3\n",
    "                # self.G_N_GRU = feature_size\n",
    "\n",
    "                # # gnn node function for language\n",
    "                self.G_N_L_S2 = [300+300, 300]\n",
    "                self.G_N_A2   = ['ReLU']\n",
    "                self.G_N_B2   = bias    #true\n",
    "                self.G_N_BN2  = bn      #false\n",
    "                self.G_N_D2   = dropout #0.3\n",
    "                # self.G_N_GRU2 = feature_size\n",
    "\n",
    "                # gnn edge function1\n",
    "                self.G_E_L_S           = [feature_size*2+16, feature_size]\n",
    "                self.G_E_A             = ['ReLU']\n",
    "                self.G_E_B             = bias     # true\n",
    "                self.G_E_BN            = bn       # false\n",
    "                self.G_E_D             = dropout  # 0.3\n",
    "                self.G_E_c_std         = 1.0\n",
    "                self.G_E_c_std_factor  = 0.985      # 0.985 (LOG), 0.95 (gau)\n",
    "                self.G_E_c_epoch       = 20\n",
    "                self.G_E_c_kernel_size = 3\n",
    "                self.G_E_c_filter      = 'LOG' # 'gau', 'LOG'\n",
    "\n",
    "                # gnn edge function2 for language\n",
    "                self.G_E_L_S2 = [300*2, feature_size]\n",
    "                self.G_E_A2   = ['ReLU']\n",
    "                self.G_E_B2   = bias     #true\n",
    "                self.G_E_BN2  = bn       #false\n",
    "                self.G_E_D2   = dropout  #0.3\n",
    "\n",
    "                # gnn attention mechanism\n",
    "                self.G_A_L_S = [feature_size, 1]\n",
    "                self.G_A_A   = ['LeakyReLU']\n",
    "                self.G_A_B   = bias     #true\n",
    "                self.G_A_BN  = bn       #false\n",
    "                self.G_A_D   = dropout  #0.3\n",
    "\n",
    "                # gnn attention mechanism2 for language\n",
    "                self.G_A_L_S2 = [feature_size, 1]\n",
    "                self.G_A_A2   = ['LeakyReLU']\n",
    "                self.G_A_B2   = bias    #true\n",
    "                self.G_A_BN2  = bn      #false\n",
    "                self.G_A_D2   = dropout #0.3\n",
    "                    \n",
    "    def save_config(self):\n",
    "        model_config = {'graph_head':{}, 'graph_node':{}, 'graph_edge':{}, 'graph_attn':{}}\n",
    "        CONFIG=self.__dict__\n",
    "        for k, v in CONFIG.items():\n",
    "            if 'G_H' in k:\n",
    "                model_config['graph_head'][k]=v\n",
    "            elif 'G_N' in k:\n",
    "                model_config['graph_node'][k]=v\n",
    "            elif 'G_E' in k:\n",
    "                model_config['graph_edge'][k]=v\n",
    "            elif 'G_A' in k:\n",
    "                model_config['graph_attn'][k]=v\n",
    "            else:\n",
    "                model_config[k]=v\n",
    "        \n",
    "        return model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def get_gaussian_filter_1D(kernel_size=3, sigma=2, channels=3):\n",
    "    # Create a x, y coordinate grid of shape (kernel_size, kernel_size, 2)\n",
    "    \n",
    "    x_coord = torch.arange(kernel_size)\n",
    "    x_grid = x_coord.repeat(kernel_size).view(kernel_size, kernel_size)\n",
    "    y_grid = x_grid.t()\n",
    "\n",
    "    xy_grid = torch.stack([x_grid, y_grid], dim=-1).float()\n",
    "    mean = (kernel_size - 1)/2.\n",
    "    variance = sigma**2.\n",
    "    xy_grid = torch.sum((xy_grid[:kernel_size,:kernel_size,:] - mean)**2., dim=-1)\n",
    "\n",
    "    # Calculate the 1-dimensional gaussian kernel\n",
    "    gaussian_kernel = (1./((math.sqrt(2.*math.pi)*sigma))) * \\\n",
    "                        torch.exp(-1* (xy_grid[int(kernel_size/2)]) / (2*variance))\n",
    "\n",
    "    gaussian_kernel = gaussian_kernel / torch.sum(gaussian_kernel)\n",
    "    gaussian_kernel = gaussian_kernel.view(1, 1, kernel_size)\n",
    "    gaussian_kernel = gaussian_kernel.repeat(channels, 1, 1)\n",
    "\n",
    "    padding = 1 if kernel_size==3 else 2 if kernel_size == 5 else 0\n",
    "    gaussian_filter = nn.Conv1d(in_channels=channels, out_channels=channels,\n",
    "                                kernel_size=kernel_size, groups=channels,\n",
    "                                bias=False, padding=padding)\n",
    "    gaussian_filter.weight.data = gaussian_kernel\n",
    "    gaussian_filter.weight.requires_grad = False \n",
    "    return gaussian_filter\n",
    "\n",
    "def get_laplaceOfGaussian_filter_1D(kernel_size=3, sigma=2, channels=3):\n",
    "    \n",
    "    # Create a x, y coordinate grid of shape (kernel_size, kernel_size, 2)\n",
    "    x_coord = torch.arange(kernel_size)\n",
    "    x_grid = x_coord.repeat(kernel_size).view(kernel_size, kernel_size)\n",
    "    y_grid = x_grid.t()\n",
    "    xy_grid = torch.stack([x_grid, y_grid], dim=-1).float()\n",
    "    mean = (kernel_size - 1)/2.\n",
    "\n",
    "    used_sigma = sigma\n",
    "    # Calculate the 2-dimensional gaussian kernel which is\n",
    "    log_kernel = (-1./(math.pi*(used_sigma**4))) \\\n",
    "                  * (1-(torch.sum((xy_grid[int(kernel_size/2)] - mean)**2., dim=-1) / (2*(used_sigma**2)))) \\\n",
    "                  * torch.exp(-torch.sum((xy_grid[int(kernel_size/2)] - mean)**2., dim=-1) / (2*(used_sigma**2)))\n",
    "    \n",
    "    # Make sure sum of values in gaussian kernel equals 1.\n",
    "    log_kernel = log_kernel / torch.sum(log_kernel)\n",
    "    log_kernel = log_kernel.view(1, 1, kernel_size)\n",
    "    log_kernel = log_kernel.repeat(channels, 1, 1)\n",
    "\n",
    "    padding = 1 if kernel_size==3 else 2 if kernel_size == 5 else 0\n",
    "    log_filter = nn.Conv1d(in_channels=channels, out_channels=channels,\n",
    "                                kernel_size=kernel_size, groups=channels,\n",
    "                                bias=False, padding=padding)\n",
    "    log_filter.weight.data = log_kernel\n",
    "    log_filter.weight.requires_grad = False\n",
    "    return log_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Primary activation and MLP layer\n",
    "acivation:\n",
    "    Identity\n",
    "    ReLU\n",
    "    LeakyReLU\n",
    "MLP:\n",
    "    init: layer size, activation, bias, use_BN, dropout_probability\n",
    "    forward: x\n",
    "'''\n",
    "\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    '''\n",
    "    Identity class activation layer\n",
    "    x = x\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Identity,self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "def get_activation(name):\n",
    "    '''\n",
    "    get_activation sub-function\n",
    "    argument: activatoin name (eg. ReLU, Identity, LeakyReLU)\n",
    "    '''\n",
    "    if name=='ReLU': return nn.ReLU(inplace=True)\n",
    "    elif name=='Identity': return Identity()\n",
    "    elif name=='LeakyReLU': return nn.LeakyReLU(0.2,inplace=True)\n",
    "    else: assert(False), 'Not Implemented'\n",
    "    #elif name=='Tanh': return nn.Tanh()\n",
    "    #elif name=='Sigmoid': return nn.Sigmoid()\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    '''\n",
    "    Args:\n",
    "        layer_sizes: a list, [1024,1024,...]\n",
    "        activation: a list, ['ReLU', 'Tanh',...]\n",
    "        bias : bool\n",
    "        use_bn: bool\n",
    "        drop_prob: default is None, use drop out layer or not\n",
    "    '''\n",
    "    def __init__(self, layer_sizes, activation, bias=True, use_bn=False, drop_prob=None):\n",
    "        super(MLP, self).__init__()\n",
    "        self.bn = use_bn\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            layer = nn.Linear(layer_sizes[i], layer_sizes[i+1], bias=bias)\n",
    "            activate = get_activation(activation[i])\n",
    "            block = nn.Sequential(OrderedDict([(f'L{i}', layer), ]))\n",
    "            \n",
    "            # !NOTE:# Actually, it is inappropriate to use batch-normalization here\n",
    "            if use_bn:                                  \n",
    "                bn = nn.BatchNorm1d(layer_sizes[i+1])\n",
    "                block.add_module(f'B{i}', bn)\n",
    "            \n",
    "            # batch normalization is put before activation function \n",
    "            block.add_module(f'A{i}', activate)\n",
    "\n",
    "            # dropout probablility\n",
    "            if drop_prob:\n",
    "                block.add_module(f'D{i}', nn.Dropout(drop_prob))\n",
    "            \n",
    "            self.layers.append(block)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # !NOTE: sometime the shape of x will be [1,N], and we cannot use batch-normailzation in that situation\n",
    "            if self.bn and x.shape[0]==1:\n",
    "                x = layer[0](x)\n",
    "                x = layer[:-1](x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "H_H_EdgeApplyModule\n",
    "    init    : config, multi_attn \n",
    "    forward : edge\n",
    "    \n",
    "H_NodeApplyModule\n",
    "    init    : config\n",
    "    forward : node\n",
    "    \n",
    "E_AttentionModule1\n",
    "    init    : config\n",
    "    forward : edge\n",
    "    \n",
    "GNN\n",
    "    init    : config, multi_attn, diff_edge\n",
    "    forward : g, h_node, o_node, h_h_e_list, o_o_e_list, h_o_e_list, pop_features\n",
    "    \n",
    "GRNN\n",
    "    init    : config, multi_attn, diff_edge\n",
    "    forward : b_graph, b_h_node_list, b_o_node_list, b_h_h_e_list, b_o_o_e_list, b_h_o_e_list, features, spatial_features, word2vec, valid, pop_features, initial_features\n",
    "'''\n",
    "\n",
    "import ipdb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class H_H_EdgeApplyModule(nn.Module): #human to human edge\n",
    "    '''\n",
    "        init    : config, multi_attn \n",
    "        forward : edge\n",
    "    '''\n",
    "    def __init__(self, CONFIG, multi_attn=False, use_cbs = False):\n",
    "        super(H_H_EdgeApplyModule, self).__init__()\n",
    "        self.use_cbs = use_cbs\n",
    "        if use_cbs:\n",
    "            self.init_std = CONFIG.G_E_c_std \n",
    "            self.cbs_std = CONFIG.G_E_c_std\n",
    "            self.cbs_std_factor = CONFIG.G_E_c_std_factor\n",
    "            self.cbs_epoch = CONFIG.G_E_c_epoch\n",
    "            self.cbs_kernel_size = CONFIG.G_E_c_kernel_size\n",
    "            self.cbs_filter = CONFIG.G_E_c_filter\n",
    "        \n",
    "        self.edge_fc = MLP(CONFIG.G_E_L_S, CONFIG.G_E_A, CONFIG.G_E_B, CONFIG.G_E_BN, CONFIG.G_E_D)\n",
    "        self.edge_fc_lang = MLP(CONFIG.G_E_L_S2, CONFIG.G_E_A2, CONFIG.G_E_B2, CONFIG.G_E_BN2, CONFIG.G_E_D2)\n",
    "    \n",
    "    def forward(self, edge):\n",
    "        feat = torch.cat([edge.src['n_f'], edge.data['s_f'], edge.dst['n_f']], dim=1)\n",
    "        feat_lang = torch.cat([edge.src['word2vec'], edge.dst['word2vec']], dim=1)\n",
    "        if self.use_cbs:\n",
    "            feat = self.kernel1(feat[:,None,:])\n",
    "            feat = torch.squeeze(feat, 1)\n",
    "        e_feat = self.edge_fc(feat)\n",
    "        e_feat_lang = self.edge_fc_lang(feat_lang)\n",
    "  \n",
    "        return {'e_f': e_feat, 'e_f_lang': e_feat_lang}\n",
    "\n",
    "    def get_new_kernels(self, epoch_count):\n",
    "        if self.use_cbs:\n",
    "            if epoch_count == 0:\n",
    "                self.cbs_std = self.init_std\n",
    "                \n",
    "            if epoch_count % self.cbs_epoch == 0 and epoch_count is not 0:\n",
    "                self.cbs_std *= self.cbs_std_factor\n",
    "            \n",
    "            if (self.cbs_filter == 'gau'): \n",
    "                self.kernel1 = get_gaussian_filter_1D(kernel_size=self.cbs_kernel_size, sigma= self.cbs_std, channels= 1)\n",
    "            elif (self.cbs_filter == 'LOG'): \n",
    "                self.kernel1 = get_laplaceOfGaussian_filter_1D(kernel_size=self.cbs_kernel_size, sigma= self.cbs_std, channels= 1)\n",
    "\n",
    "class H_NodeApplyModule(nn.Module): #human node\n",
    "    '''\n",
    "        init    : config\n",
    "        forward : node\n",
    "    '''\n",
    "    def __init__(self, CONFIG):\n",
    "        super(H_NodeApplyModule, self).__init__()\n",
    "        self.node_fc = MLP(CONFIG.G_N_L_S, CONFIG.G_N_A, CONFIG.G_N_B, CONFIG.G_N_BN, CONFIG.G_N_D)\n",
    "        self.node_fc_lang = MLP(CONFIG.G_N_L_S2, CONFIG.G_N_A2, CONFIG.G_N_B2, CONFIG.G_N_BN2, CONFIG.G_N_D2)\n",
    "    \n",
    "    def forward(self, node):\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        feat = torch.cat([node.data['n_f'], node.data['z_f']], dim=1)\n",
    "        feat_lang = torch.cat([node.data['word2vec'], node.data['z_f_lang']], dim=1)\n",
    "        n_feat = self.node_fc(feat)\n",
    "        n_feat_lang = self.node_fc_lang(feat_lang)\n",
    "\n",
    "        return {'new_n_f': n_feat, 'new_n_f_lang': n_feat_lang}\n",
    "\n",
    "class E_AttentionModule1(nn.Module): #edge attention\n",
    "    '''\n",
    "        init    : config\n",
    "        forward : edge\n",
    "    '''\n",
    "    def __init__(self, CONFIG):\n",
    "        super(E_AttentionModule1, self).__init__()\n",
    "        self.attn_fc = MLP(CONFIG.G_A_L_S, CONFIG.G_A_A, CONFIG.G_A_B, CONFIG.G_A_BN, CONFIG.G_A_D)\n",
    "        self.attn_fc_lang = MLP(CONFIG.G_A_L_S2, CONFIG.G_A_A2, CONFIG.G_A_B2, CONFIG.G_A_BN2, CONFIG.G_A_D2)\n",
    "\n",
    "    def forward(self, edge):\n",
    "        a_feat = self.attn_fc(edge.data['e_f'])\n",
    "        a_feat_lang = self.attn_fc_lang(edge.data['e_f_lang'])\n",
    "        return {'a_feat': a_feat, 'a_feat_lang': a_feat_lang}\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    '''\n",
    "        init    : config, multi_attn, diff_edge\n",
    "        forward : g, h_node, o_node, h_h_e_list, o_o_e_list, h_o_e_list, pop_features\n",
    "    '''\n",
    "    def __init__(self, CONFIG, multi_attn=False, diff_edge=True, use_cbs = False):\n",
    "        super(GNN, self).__init__()\n",
    "        self.diff_edge = diff_edge # false\n",
    "        self.apply_h_h_edge = H_H_EdgeApplyModule(CONFIG, multi_attn, use_cbs)\n",
    "        self.apply_edge_attn1 = E_AttentionModule1(CONFIG)  \n",
    "        self.apply_h_node = H_NodeApplyModule(CONFIG)\n",
    "\n",
    "    def _message_func(self, edges):\n",
    "        return {'nei_n_f': edges.src['n_f'], 'nei_n_w': edges.src['word2vec'], 'e_f': edges.data['e_f'], 'e_f_lang': edges.data['e_f_lang'], 'a_feat': edges.data['a_feat'], 'a_feat_lang': edges.data['a_feat_lang']}\n",
    "\n",
    "    def _reduce_func(self, nodes):\n",
    "        alpha = F.softmax(nodes.mailbox['a_feat'], dim=1)\n",
    "        alpha_lang = F.softmax(nodes.mailbox['a_feat_lang'], dim=1)\n",
    "\n",
    "        z_raw_f = nodes.mailbox['nei_n_f']+nodes.mailbox['e_f']\n",
    "        z_f = torch.sum( alpha * z_raw_f, dim=1)\n",
    "\n",
    "        z_raw_f_lang = nodes.mailbox['nei_n_w']\n",
    "        z_f_lang = torch.sum(alpha_lang * z_raw_f_lang, dim=1)\n",
    "         \n",
    "        # we cannot return 'alpha' for the different dimension \n",
    "        if self.training or validation: return {'z_f': z_f, 'z_f_lang': z_f_lang}\n",
    "        else: return {'z_f': z_f, 'z_f_lang': z_f_lang, 'alpha': alpha, 'alpha_lang': alpha_lang}\n",
    "\n",
    "    def forward(self, g, h_node, o_node, h_h_e_list, o_o_e_list, h_o_e_list, pop_feat=False):\n",
    "        \n",
    "        g.apply_edges(self.apply_h_h_edge, g.edges())\n",
    "        g.apply_edges(self.apply_edge_attn1)\n",
    "        g.update_all(self._message_func, self._reduce_func)\n",
    "        g.apply_nodes(self.apply_h_node, h_node+o_node)\n",
    "\n",
    "        # !NOTE:PAY ATTENTION WHEN ADDING MORE FEATURE\n",
    "        g.ndata.pop('n_f')\n",
    "        g.ndata.pop('word2vec')\n",
    "\n",
    "        g.ndata.pop('z_f')\n",
    "        g.edata.pop('e_f')\n",
    "        g.edata.pop('a_feat')\n",
    "\n",
    "        g.ndata.pop('z_f_lang')\n",
    "        g.edata.pop('e_f_lang')\n",
    "        g.edata.pop('a_feat_lang')\n",
    "\n",
    "class GRNN(nn.Module):\n",
    "    '''\n",
    "    init: \n",
    "        config, multi_attn, diff_edge\n",
    "    forward: \n",
    "        batch_graph, batch_h_node_list, batch_obj_node_list,\n",
    "        batch_h_h_e_list, batch_o_o_e_list, batch_h_o_e_list,\n",
    "        features, spatial_features, word2vec,\n",
    "        valid, pop_features, initial_features\n",
    "    '''\n",
    "    def __init__(self, CONFIG, multi_attn=False, diff_edge=True, use_cbs = False):\n",
    "        super(GRNN, self).__init__()\n",
    "        self.multi_attn = multi_attn #false\n",
    "        self.gnn = GNN(CONFIG, multi_attn, diff_edge, use_cbs)\n",
    "\n",
    "    def forward(self, batch_graph, batch_h_node_list, batch_obj_node_list, batch_h_h_e_list, batch_o_o_e_list, batch_h_o_e_list, feat, spatial_feat, word2vec, valid=False, pop_feat=False, initial_feat=False):\n",
    "        \n",
    "        # !NOTE: if node_num==1, there will be something wrong to forward the attention mechanism\n",
    "        global validation \n",
    "        validation = valid\n",
    "\n",
    "        # initialize the graph with some datas\n",
    "        batch_graph.ndata['n_f'] = feat           # node: features \n",
    "        batch_graph.ndata['word2vec'] = word2vec  # node: words\n",
    "        batch_graph.edata['s_f'] = spatial_feat   # edge: spatial features\n",
    "\n",
    "        try:\n",
    "            self.gnn(batch_graph, batch_h_node_list, batch_obj_node_list, batch_h_h_e_list, batch_o_o_e_list, batch_h_o_e_list)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            ipdb.set_trace()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Predictor \n",
    "    init    : config\n",
    "    forward : edge\n",
    "\n",
    "AGRNN\n",
    "    init    : bias, bn, dropout, multi_attn, layer, diff_edge\n",
    "    forward : node_num, feat, spatial_feat, word2vec, roi_label, validation, choose_nodes, remove_nodes\n",
    "'''\n",
    "\n",
    "import dgl\n",
    "import ipdb\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torchvision\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    '''\n",
    "    init    : config\n",
    "    forward : edge\n",
    "    '''\n",
    "    def __init__(self, CONFIG):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.classifier = MLP(CONFIG.G_ER_L_S, CONFIG.G_ER_A, CONFIG.G_ER_B, CONFIG.G_ER_BN, CONFIG.G_ER_D)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, edge):\n",
    "        feat = torch.cat([edge.dst['new_n_f'], edge.dst['new_n_f_lang'], edge.data['s_f'], edge.src['new_n_f_lang'], edge.src['new_n_f']], dim=1)\n",
    "        pred = self.classifier(feat)\n",
    "        # if the criterion is BCELoss, you need to uncomment the following code\n",
    "        # output = self.sigmoid(output)\n",
    "        return {'pred': pred}\n",
    "\n",
    "class AGRNN(nn.Module):\n",
    "    '''\n",
    "    init    : \n",
    "        feature_type, bias, bn, dropout, multi_attn, layer, diff_edge\n",
    "        \n",
    "    forward : \n",
    "        node_num, features, spatial_features, word2vec, roi_label,\n",
    "        validation, choose_nodes, remove_nodes\n",
    "    '''\n",
    "    def __init__(self, bias=True, bn=True, dropout=None, multi_attn=False, layer=1, diff_edge=True, use_cbs = False):\n",
    "        super(AGRNN, self).__init__()\n",
    " \n",
    "        self.multi_attn = multi_attn # false\n",
    "        self.layer = layer           # 1 layer\n",
    "        self.diff_edge = diff_edge   # false\n",
    "        \n",
    "        self.CONFIG1 = CONFIGURATION(layer=1, bias=bias, bn=bn, dropout=dropout, multi_attn=multi_attn)\n",
    "\n",
    "        self.grnn1 = GRNN(self.CONFIG1, multi_attn=multi_attn, diff_edge=diff_edge, use_cbs = use_cbs)\n",
    "        self.edge_readout = Predictor(self.CONFIG1)\n",
    "        \n",
    "    def _collect_edge(self, node_num, roi_label, node_space, diff_edge):\n",
    "        '''\n",
    "        arguments: node_num, roi_label, node_space, diff_edge\n",
    "        '''\n",
    "        \n",
    "        # get human nodes && object nodes\n",
    "        h_node_list = np.where(roi_label == 0)[0]\n",
    "        obj_node_list = np.where(roi_label != 0)[0]\n",
    "        edge_list = []\n",
    "        \n",
    "        h_h_e_list = []\n",
    "        o_o_e_list = []\n",
    "        h_o_e_list = []\n",
    "        \n",
    "        readout_edge_list = []\n",
    "        readout_h_h_e_list = []\n",
    "        readout_h_o_e_list = []\n",
    "        \n",
    "        # get all edge in the fully-connected graph, edge_list, For node_num = 2, edge_list = [(0, 1), (1, 0)]\n",
    "        for src in range(node_num):\n",
    "            for dst in range(node_num):\n",
    "                if src == dst:\n",
    "                    continue\n",
    "                else:\n",
    "                    edge_list.append((src, dst))\n",
    "        \n",
    "        # readout_edge_list, get corresponding readout edge in the graph\n",
    "        src_box_list = np.arange(roi_label.shape[0])\n",
    "        for dst in h_node_list:\n",
    "            # if dst == roi_label.shape[0]-1:\n",
    "            #    continue\n",
    "            # src_box_list = src_box_list[1:]\n",
    "            for src in src_box_list:\n",
    "                if src not in h_node_list:\n",
    "                    readout_edge_list.append((src, dst))\n",
    "        \n",
    "        # readout h_h_e_list, get corresponding readout h_h edges && h_o edges\n",
    "        temp_h_node_list = h_node_list[:]\n",
    "        for dst in h_node_list:\n",
    "            if dst == h_node_list.shape[0]-1:\n",
    "                continue\n",
    "            temp_h_node_list = temp_h_node_list[1:]\n",
    "            for src in temp_h_node_list:\n",
    "                if src == dst: continue\n",
    "                readout_h_h_e_list.append((src, dst))\n",
    "\n",
    "        # readout h_o_e_list\n",
    "        readout_h_o_e_list = [x for x in readout_edge_list if x not in readout_h_h_e_list]\n",
    "\n",
    "        # add node space to match the batch graph\n",
    "        h_node_list = (np.array(h_node_list)+node_space).tolist()\n",
    "        obj_node_list = (np.array(obj_node_list)+node_space).tolist()\n",
    "        \n",
    "        h_h_e_list = (np.array(h_h_e_list)+node_space).tolist() #empty no diff_edge\n",
    "        o_o_e_list = (np.array(o_o_e_list)+node_space).tolist() #empty no diff_edge\n",
    "        h_o_e_list = (np.array(h_o_e_list)+node_space).tolist() #empty no diff_edge\n",
    "\n",
    "        readout_h_h_e_list = (np.array(readout_h_h_e_list)+node_space).tolist()\n",
    "        readout_h_o_e_list = (np.array(readout_h_o_e_list)+node_space).tolist()   \n",
    "        readout_edge_list = (np.array(readout_edge_list)+node_space).tolist()\n",
    "\n",
    "        return edge_list, h_node_list, obj_node_list, h_h_e_list, o_o_e_list, h_o_e_list, readout_edge_list, readout_h_h_e_list, readout_h_o_e_list\n",
    "    \n",
    "    def _build_graph(self, node_num, roi_label, node_space, diff_edge):\n",
    "        '''\n",
    "        Declare graph, add_nodes, collect edges, add_edges\n",
    "        '''\n",
    "        graph = dgl.DGLGraph()\n",
    "        graph.add_nodes(node_num)\n",
    "\n",
    "        edge_list, h_node_list, obj_node_list, h_h_e_list, o_o_e_list, h_o_e_list, readout_edge_list, readout_h_h_e_list, readout_h_o_e_list = self._collect_edge(node_num, roi_label, node_space, diff_edge)\n",
    "        src, dst = tuple(zip(*edge_list))\n",
    "        graph.add_edges(src, dst)   # make the graph bi-directional\n",
    "\n",
    "        return graph, h_node_list, obj_node_list, h_h_e_list, o_o_e_list, h_o_e_list, readout_edge_list, readout_h_h_e_list, readout_h_o_e_list\n",
    "\n",
    "    def forward(self, node_num=None, feat=None, spatial_feat=None, word2vec=None, roi_label=None, validation=False, choose_nodes=None, remove_nodes=None):\n",
    "        \n",
    "        batch_graph, batch_h_node_list, batch_obj_node_list, batch_h_h_e_list, batch_o_o_e_list, batch_h_o_e_list, batch_readout_edge_list, batch_readout_h_h_e_list, batch_readout_h_o_e_list = [], [], [], [], [], [], [], [], []\n",
    "        node_num_cum = np.cumsum(node_num) # !IMPORTANT\n",
    "        \n",
    "        for i in range(len(node_num)):\n",
    "            # set node space\n",
    "            node_space = 0\n",
    "            if i != 0:\n",
    "                node_space = node_num_cum[i-1]\n",
    "            graph, h_node_list, obj_node_list, h_h_e_list, o_o_e_list, h_o_e_list, readout_edge_list, readout_h_h_e_list, readout_h_o_e_list = self._build_graph(node_num[i], roi_label[i], node_space, diff_edge=self.diff_edge)\n",
    "            \n",
    "            # updata batch\n",
    "            batch_graph.append(graph)\n",
    "            batch_h_node_list += h_node_list\n",
    "            batch_obj_node_list += obj_node_list\n",
    "            \n",
    "            batch_h_h_e_list += h_h_e_list\n",
    "            batch_o_o_e_list += o_o_e_list\n",
    "            batch_h_o_e_list += h_o_e_list\n",
    "            \n",
    "            batch_readout_edge_list += readout_edge_list\n",
    "            batch_readout_h_h_e_list += readout_h_h_e_list\n",
    "            batch_readout_h_o_e_list += readout_h_o_e_list\n",
    "        \n",
    "        batch_graph = dgl.batch(batch_graph)\n",
    "        \n",
    "        # GRNN\n",
    "        self.grnn1(batch_graph, batch_h_node_list, batch_obj_node_list, batch_h_h_e_list, batch_o_o_e_list, batch_h_o_e_list, feat, spatial_feat, word2vec, validation, initial_feat=True)\n",
    "        batch_graph.apply_edges(self.edge_readout, tuple(zip(*(batch_readout_h_o_e_list+batch_readout_h_h_e_list))))\n",
    "        \n",
    "        if self.training or validation:\n",
    "            # !NOTE: cannot use \"batch_readout_h_o_e_list+batch_readout_h_h_e_list\" because of the wrong order\n",
    "            return batch_graph.edges[tuple(zip(*batch_readout_edge_list))].data['pred']\n",
    "        else:\n",
    "            return batch_graph.edges[tuple(zip(*batch_readout_edge_list))].data['pred'], \\\n",
    "                   batch_graph.nodes[batch_h_node_list].data['alpha'], \\\n",
    "                   batch_graph.nodes[batch_h_node_list].data['alpha_lang'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils.io as io\n",
    "\n",
    "class SurgicalSceneConstants():\n",
    "    def __init__( self):\n",
    "        self.instrument_classes = ('kidney', 'bipolar_forceps', 'prograsp_forceps', 'large_needle_driver',\n",
    "                      'monopolar_curved_scissors', 'ultrasound_probe', 'suction', 'clip_applier',\n",
    "                      'stapler', 'maryland_dissector', 'spatulated_monopolar_cautery')\n",
    "        \n",
    "        #self.instrument_classes = ( 'kidney', 'bipolar_forceps', 'fenestrated_bipolar', \n",
    "        #                             'prograsp_forceps', 'large_needle_driver', 'vessel_sealer',\n",
    "        #                             'grasping_retractor', 'monopolar_curved_scissors', \n",
    "        #                             'ultrasound_probe', 'suction', 'clip_applier', 'stapler')\n",
    "        \n",
    "        self.action_classes = ( 'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation', \n",
    "                                'Tool_Manipulation', 'Cutting', 'Cauterization', \n",
    "                                'Suction', 'Looping', 'Suturing', 'Clipping', 'Staple', \n",
    "                                'Ultrasound_Sensing')\n",
    "        self.xml_data_dir = 'datasets/instruments18/seq_'\n",
    "        self.word2vec_loc = 'datasets/surgicalscene_word2vec.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "    \n",
    "class SurgicalSceneDataset(Dataset):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self, seq_set, data_dir, img_dir, dset, dataconst, feature_extractor, reduce_size = False):\n",
    "        \n",
    "        \n",
    "        self.data_size = 143\n",
    "        self.dataconst = dataconst\n",
    "        self.img_dir = img_dir\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.reduce_size = reduce_size\n",
    "        \n",
    "        self.xml_dir_list = []\n",
    "        self.dset = []\n",
    "        \n",
    "        for domain in range(len(seq_set)):\n",
    "            domain_dir_list = []\n",
    "            for i in seq_set[domain]:\n",
    "                xml_dir_temp = data_dir[domain] + str(i) + '/xml/'\n",
    "                domain_dir_list = domain_dir_list + glob(xml_dir_temp + '/*.xml')\n",
    "            if self.reduce_size:\n",
    "                indices = np.random.permutation(len(domain_dir_list))\n",
    "                domain_dir_list = [domain_dir_list[j] for j in indices[0:self.data_size]]\n",
    "            for file in domain_dir_list: \n",
    "                self.xml_dir_list.append(file)\n",
    "                self.dset.append(dset[domain])\n",
    "        self.word2vec = h5py.File('datasets/surgicalscene_word2vec.hdf5', 'r')\n",
    "    \n",
    "    # word2vec\n",
    "    def _get_word2vec(self,node_ids, sgh = 0):\n",
    "        word2vec = np.empty((0,300))\n",
    "        for node_id in node_ids:\n",
    "            if sgh == 1 and node_id == 0:\n",
    "                vec = self.word2vec['tissue']\n",
    "            else:\n",
    "                vec = self.word2vec[self.dataconst.instrument_classes[node_id]]\n",
    "            word2vec = np.vstack((word2vec, vec))\n",
    "        return word2vec\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xml_dir_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "    \n",
    "        file_name = os.path.splitext(os.path.basename(self.xml_dir_list[idx]))[0]\n",
    "        file_root = os.path.dirname(os.path.dirname(self.xml_dir_list[idx]))\n",
    "        if len(self.img_dir) == 1:\n",
    "            _img_loc = os.path.join(file_root+self.img_dir[0]+ file_name + '.png')\n",
    "        else:\n",
    "            _img_loc = os.path.join(file_root+self.img_dir[self.dset[idx]]+ file_name + '.png')\n",
    "        frame_data = h5py.File(os.path.join(file_root+'/vsgat/'+self.feature_extractor+'/'+ file_name + '_features.hdf5'), 'r')    \n",
    "        data = {}\n",
    "        data['img_name'] = frame_data['img_name'].value[:] + '.jpg'\n",
    "        data['img_loc'] = _img_loc\n",
    "        \n",
    "        data['node_num'] = frame_data['node_num'].value\n",
    "        data['roi_labels'] = frame_data['classes'][:]\n",
    "        data['det_boxes'] = frame_data['boxes'][:]\n",
    "        \n",
    "        \n",
    "        data['edge_labels'] = frame_data['edge_labels'][:]\n",
    "        data['edge_num'] = data['edge_labels'].shape[0]\n",
    "        \n",
    "        data['features'] = frame_data['node_features'][:]\n",
    "        data['spatial_feat'] = frame_data['spatial_features'][:]\n",
    "        \n",
    "        \n",
    "        data['word2vec'] = self._get_word2vec(data['roi_labels'], self.dset[idx])\n",
    "        return data\n",
    "\n",
    "# for DatasetLoader\n",
    "def collate_fn(batch):\n",
    "    '''\n",
    "        Default collate_fn(): https://github.com/pytorch/pytorch/blob/1d53d0756668ce641e4f109200d9c65b003d05fa/torch/utils/data/_utils/collate.py#L43\n",
    "    '''\n",
    "    batch_data = {}\n",
    "    batch_data['img_name'] = []\n",
    "    batch_data['img_loc'] = []\n",
    "    batch_data['node_num'] = []\n",
    "    batch_data['roi_labels'] = []\n",
    "    batch_data['det_boxes'] = []\n",
    "    batch_data['edge_labels'] = []\n",
    "    batch_data['edge_num'] = []\n",
    "    batch_data['features'] = []\n",
    "    batch_data['spatial_feat'] = []\n",
    "    batch_data['word2vec'] = []\n",
    "    \n",
    "    for data in batch:\n",
    "        batch_data['img_name'].append(data['img_name'])\n",
    "        batch_data['img_loc'].append(data['img_loc'])\n",
    "        batch_data['node_num'].append(data['node_num'])\n",
    "        batch_data['roi_labels'].append(data['roi_labels'])\n",
    "        batch_data['det_boxes'].append(data['det_boxes'])\n",
    "        batch_data['edge_labels'].append(data['edge_labels'])\n",
    "        batch_data['edge_num'].append(data['edge_num'])\n",
    "        batch_data['features'].append(data['features'])\n",
    "        batch_data['spatial_feat'].append(data['spatial_feat'])\n",
    "        batch_data['word2vec'].append(data['word2vec'])\n",
    "        \n",
    "    batch_data['edge_labels'] = torch.FloatTensor(np.concatenate(batch_data['edge_labels'], axis=0))\n",
    "    batch_data['features'] = torch.FloatTensor(np.concatenate(batch_data['features'], axis=0))\n",
    "    batch_data['spatial_feat'] = torch.FloatTensor(np.concatenate(batch_data['spatial_feat'], axis=0))\n",
    "    batch_data['word2vec'] = torch.FloatTensor(np.concatenate(batch_data['word2vec'], axis=0))\n",
    "    \n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import torch as t\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plot\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "def vis_img(img, node_classes, bboxs,  det_action, score_thresh = 0.7):\n",
    "    \n",
    "    Drawer = ImageDraw.Draw(img)\n",
    "    line_width = 3\n",
    "    outline = '#FF0000'\n",
    "    font = ImageFont.truetype(font='/usr/share/fonts/truetype/freefont/FreeMono.ttf', size=25)\n",
    "    \n",
    "    im_w,im_h = img.size\n",
    "    node_num = len(node_classes)\n",
    "    edge_num = len(det_action)\n",
    "    tissue_num = len(np.where(node_classes == 1)[0])\n",
    "    \n",
    "    for node in range(node_num):\n",
    "        \n",
    "        r_color = random.choice(np.arange(256))\n",
    "        g_color = random.choice(np.arange(256))\n",
    "        b_color = random.choice(np.arange(256))\n",
    "        \n",
    "        text = data_const.instrument_classes[node_classes[node]]\n",
    "        h, w = font.getsize(text)\n",
    "        Drawer.rectangle(list(bboxs[node]), outline=outline, width=line_width)\n",
    "        Drawer.text(xy=(bboxs[node][0], bboxs[node][1]-w-1), text=text, font=font, fill=(r_color,g_color,b_color))\n",
    "  \n",
    "    edge_idx = 0\n",
    "    \n",
    "    for tissue in range(tissue_num):\n",
    "        for instrument in range(tissue+1, node_num):\n",
    "            \n",
    "            #action_idx = np.where(det_action[edge_idx] > score_thresh)[0]\n",
    "            action_idx = np.argmax(det_action[edge_idx])\n",
    "#             print('det_action', det_action[edge_idx])\n",
    "#             print('action_idx',action_idx)\n",
    "            \n",
    "            text = data_const.action_classes[action_idx]\n",
    "            r_color = random.choice(np.arange(256))\n",
    "            g_color = random.choice(np.arange(256))\n",
    "            b_color = random.choice(np.arange(256))\n",
    "        \n",
    "            x1,y1,x2,y2 = bboxs[tissue]\n",
    "            x1_,y1_,x2_,y2_ = bboxs[instrument]\n",
    "            \n",
    "            c0 = int(0.5*x1)+int(0.5*x2)\n",
    "            c0 = max(0,min(c0,im_w-1))\n",
    "            r0 = int(0.5*y1)+int(0.5*y2)\n",
    "            r0 = max(0,min(r0,im_h-1))\n",
    "            c1 = int(0.5*x1_)+int(0.5*x2_)\n",
    "            c1 = max(0,min(c1,im_w-1))\n",
    "            r1 = int(0.5*y1_)+int(0.5*y2_)\n",
    "            r1 = max(0,min(r1,im_h-1))\n",
    "            Drawer.line(((c0,r0),(c1,r1)), fill=(r_color,g_color,b_color), width=3)\n",
    "            Drawer.text(xy=(c1, r1), text=text, font=font, fill=(r_color,g_color,b_color))\n",
    "\n",
    "            edge_idx +=1\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import sklearn.metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def ece_eval(preds, targets, n_bins=10, bg_cls = 0):\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    confidences, predictions = np.max(preds,1), np.argmax(preds,1)\n",
    "    confidences, predictions = confidences[targets>bg_cls], predictions[targets>bg_cls]\n",
    "    accuracies = (predictions == targets[targets>bg_cls]) \n",
    "    Bm, acc, conf = np.zeros(n_bins), np.zeros(n_bins), np.zeros(n_bins)\n",
    "    ece = 0.0\n",
    "    bin_idx = 0\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = np.logical_and(confidences > bin_lower, confidences <= bin_upper)\n",
    "        #in_bin = in_bin[targets>backgound_class]\n",
    "        bin_size = np.sum(in_bin)\n",
    "        \n",
    "        Bm[bin_idx] = bin_size\n",
    "        if bin_size > 0:  \n",
    "            accuracy_in_bin = np.sum(accuracies[in_bin])\n",
    "            acc[bin_idx] = accuracy_in_bin / Bm[bin_idx]\n",
    "            confidence_in_bin = np.sum(confidences[in_bin])\n",
    "            conf[bin_idx] = confidence_in_bin / Bm[bin_idx]\n",
    "        bin_idx += 1\n",
    "        \n",
    "    ece_all = Bm * np.abs((acc - conf))/ Bm.sum()\n",
    "    ece = ece_all.sum() \n",
    "    return ece, acc, conf, Bm\n",
    "\n",
    "def get_sce(preds, targets, n_bins=10, **args):\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    \n",
    "    n_objects, n_classes = preds.shape\n",
    "    res = 0.0\n",
    "    for cur_class in range(n_classes):\n",
    "        for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "            cur_class_conf = preds[:, cur_class]\n",
    "            in_bin = np.logical_and(cur_class_conf > bin_lower, cur_class_conf <= bin_upper)\n",
    "\n",
    "            # cur_class_acc is ground truth probability of chosen class being the correct one inside the bin.\n",
    "            # NOT fraction of correct predictions in the bin\n",
    "            # because it is compared with predicted probability\n",
    "            bin_acc = (targets[in_bin] == cur_class)\n",
    "            \n",
    "            bin_conf = cur_class_conf[in_bin]\n",
    "\n",
    "            bin_size = np.sum(in_bin)\n",
    "            \n",
    "            if bin_size > 0:\n",
    "                avg_confidence_in_bin = np.mean(bin_conf)\n",
    "                avg_accuracy_in_bin = np.mean(bin_acc)\n",
    "                delta = np.abs(avg_confidence_in_bin - avg_accuracy_in_bin)\n",
    "#                 print(f'bin size {bin_size}, bin conf {avg_confidence_in_bin}, bin acc {avg_accuracy_in_bin}')\n",
    "                res += delta * bin_size / (n_objects * n_classes)\n",
    "    return res\n",
    "\n",
    "def get_tace(preds, targets, n_bins=15, threshold=1e-3, **args):\n",
    "    n_objects, n_classes = preds.shape\n",
    "    \n",
    "    res = 0.0\n",
    "    for cur_class in range(n_classes):\n",
    "        cur_class_conf = preds[:, cur_class]\n",
    "        \n",
    "        targets_sorted = targets[cur_class_conf.argsort()]\n",
    "        cur_class_conf_sorted = np.sort(cur_class_conf)\n",
    "        \n",
    "        targets_sorted = targets_sorted[cur_class_conf_sorted > threshold]\n",
    "        cur_class_conf_sorted = cur_class_conf_sorted[cur_class_conf_sorted > threshold]\n",
    "        \n",
    "        bin_size = len(cur_class_conf_sorted) // n_bins\n",
    "                \n",
    "        for bin_i in range(n_bins):\n",
    "            bin_start_ind = bin_i * bin_size\n",
    "            if bin_i < n_bins-1:\n",
    "                bin_end_ind = bin_start_ind + bin_size\n",
    "            else:\n",
    "                bin_end_ind = len(targets_sorted)\n",
    "                bin_size = bin_end_ind - bin_start_ind  # extend last bin until the end of prediction array\n",
    "            bin_acc = (targets_sorted[bin_start_ind : bin_end_ind] == cur_class)\n",
    "            bin_conf = cur_class_conf_sorted[bin_start_ind : bin_end_ind]\n",
    "            avg_confidence_in_bin = np.mean(bin_conf)\n",
    "            avg_accuracy_in_bin = np.mean(bin_acc)\n",
    "            delta = np.abs(avg_confidence_in_bin - avg_accuracy_in_bin)\n",
    "#             print(f'bin size {bin_size}, bin conf {avg_confidence_in_bin}, bin acc {avg_accuracy_in_bin}')\n",
    "            res += delta * bin_size / (n_objects * n_classes)\n",
    "            \n",
    "    return res\n",
    "\n",
    "def get_brier(preds, targets, **args):\n",
    "    one_hot_targets = np.zeros(preds.shape)\n",
    "    one_hot_targets[np.arange(len(targets)), targets] = 1.0\n",
    "    return np.mean(np.sum((preds - one_hot_targets) ** 2, axis=1))\n",
    "\n",
    "def nentr(p, base=None):\n",
    "    \"\"\"\n",
    "    Calculates entropy of p to the base b. If base is None, the natural logarithm is used.\n",
    "    :param p: batches of class label probability distributions (softmax output)\n",
    "    :param base: base b\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    eps = torch.tensor([1e-16], device=p.device)\n",
    "    if base:\n",
    "        base = torch.tensor([base], device=p.device, dtype=torch.float32)\n",
    "        return (p.mul(p.add(eps).log().div(base.log()))).sum(dim=1).abs()\n",
    "    else:\n",
    "        return (p.mul(p.add(eps).log())).sum(dim=1).abs()\n",
    "\n",
    "def uceloss(softmaxes, labels, n_bins=15):\n",
    "    d = softmaxes.device\n",
    "    bin_boundaries = torch.linspace(0, 1, n_bins + 1, device=d)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    _, predictions = torch.max(softmaxes, 1)\n",
    "    _, labels = torch.max(labels, 1)\n",
    "    errors = predictions.ne(labels)\n",
    "    uncertainties = nentr(softmaxes, base=softmaxes.size(1))\n",
    "    errors_in_bin_list = []\n",
    "    avg_entropy_in_bin_list = []\n",
    "\n",
    "    uce = torch.zeros(1)\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        # Calculate |uncert - err| in each bin\n",
    "        in_bin = uncertainties.gt(bin_lower.item()) * uncertainties.le(bin_upper.item())\n",
    "        prop_in_bin = in_bin.float().mean()  # |Bm| / n\n",
    "        if prop_in_bin.item() > 0.0:\n",
    "            errors_in_bin = errors[in_bin].float().mean()  # err()\n",
    "            avg_entropy_in_bin = uncertainties[in_bin].mean()  # uncert()\n",
    "            uce += torch.abs(avg_entropy_in_bin - errors_in_bin) * prop_in_bin\n",
    "\n",
    "            errors_in_bin_list.append(errors_in_bin)\n",
    "            avg_entropy_in_bin_list.append(avg_entropy_in_bin)\n",
    "\n",
    "    err_in_bin = torch.tensor(errors_in_bin_list, device=d)\n",
    "    avg_entropy_in_bin = torch.tensor(avg_entropy_in_bin_list, device=d)\n",
    "\n",
    "    return uce#, err_in_bin, avg_entropy_in_bin\n",
    "\n",
    "def compute_mean_avg_prec(y_true, y_score):\n",
    "    try:\n",
    "        avg_prec = sklearn.metrics.average_precision_score(y_true, y_score, average=None)\n",
    "        mean_avg_prec = np.nansum(avg_prec) / len(avg_prec)\n",
    "    except ValueError:\n",
    "        mean_avg_prec = 0\n",
    "\n",
    "    return mean_avg_prec\n",
    "\n",
    "def reliability_diagram_multi(conf_avg, acc_avg, rdname, legend=None, leg_idx=0, n_bins=10):\n",
    "    #plt.clf()\n",
    "    plt.figure(2)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(np.arange(0, 1.1, 1/n_bins))\n",
    "    #plt.title(title)\n",
    "    plt.plot(conf_avg[acc_avg>0],acc_avg[acc_avg>0], marker='.', label = legend)\n",
    "    plt.legend()\n",
    "    plt.savefig('figures/reliability_diagram/'+rdname+'ece_rel_multi.png',dpi=300)\n",
    "    plt.savefig('figures/'+rdname+'ece_rel_multi.png',dpi=300)\n",
    "\n",
    "def calibration_metrics(logits_all, labels_all, rdname, plot=False, model_name='graph_network'):\n",
    "    uce = uceloss( logits_all.cpu(), labels_all.cpu())\n",
    "    \n",
    "    logits = logits_all.detach().cpu().numpy()\n",
    "    labels = labels_all.detach().cpu().numpy()\n",
    "    map_value = compute_mean_avg_prec(labels, logits)\n",
    "    \n",
    "    labels = np.argmax(labels, axis=-1)\n",
    "    recall = sklearn.metrics.recall_score(labels, np.argmax(logits,1), average='macro')\n",
    "    ece, acc, conf, Bm = ece_eval(logits, labels, bg_cls=-1)\n",
    "    sce = get_sce(logits, labels)\n",
    "    tace = get_tace(logits, labels)\n",
    "    brier = get_brier(logits, labels)\n",
    "    #print('%s:, ece:%0.4f, sce:%0.4f, tace:%0.4f, brier:%.4f, uce:%.4f' %(model_name, ece, sce, tace, brier, uce.item()) )\n",
    "    if plot: reliability_diagram_multi(conf, acc, rdname, legend=model_name)\n",
    "    return(map_value, recall, ece, sce, tace, brier, uce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import utils.io as io\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def seed_everything(seed=27):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def calculate_cls_freq(dataloader, num_classes):\n",
    "    cls_freq = np.zeros((num_classes,1))\n",
    "    for data in dataloader:\n",
    "        edge_labels = data['edge_labels']\n",
    "        edge_labels = np.argmax(edge_labels.cpu().data.numpy(), axis=-1)    \n",
    "        for i in edge_labels:\n",
    "            cls_freq[i] += 1\n",
    "    return cls_freq\n",
    "\n",
    "def evaluate(args, data_const, model, seq, device, dname, rdname, plot_name = 'graph',plot = False):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    train_dataset = SurgicalSceneDataset(seq_set = seq['train_seq'], data_dir = seq['data_dir'], \\\n",
    "                            img_dir = seq['img_dir'], dset = seq['dset'], dataconst = data_const, \\\n",
    "                            feature_extractor = args.feature_extractor, reduce_size = False)\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=args.batch_size, shuffle= True, \\\n",
    "                            collate_fn=collate_fn)\n",
    "    \n",
    "    val_dataset = SurgicalSceneDataset(seq_set = seq['val_seq'], data_dir = seq['data_dir'], \\\n",
    "                            img_dir = seq['img_dir'], dset = seq['dset'], dataconst = data_const, \\\n",
    "                            feature_extractor = args.feature_extractor, reduce_size = False)\n",
    "    val_dataloader = DataLoader(dataset=val_dataset, batch_size= 1, shuffle= True, \\\n",
    "                            collate_fn=collate_fn)\n",
    "    \n",
    "    # model evaluate\n",
    "    model.eval()\n",
    "    \n",
    "    # criterion and scheduler\n",
    "    criterion = nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "    # each epoch has a training and validation step                   \n",
    "    edge_count = 0\n",
    "    total_acc = 0.0\n",
    "    total_loss = 0.0\n",
    "    logits_list = []\n",
    "    labels_list = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if args.use_cda_t:\n",
    "        cls_freq = calculate_cls_freq(train_dataloader, len(data_const.action_classes))\n",
    "        cls_freq_log = torch.tensor(cls_freq).log()\n",
    "        cls_freq_log_norm = cls_freq_log/cls_freq_log.max()\n",
    "        temp = args.t_scale - (1-cls_freq_log_norm.view(-1))\n",
    "        #print(temp)\n",
    "        temp = temp.to(device)\n",
    "    \n",
    "    for data in val_dataloader:\n",
    "        train_data = data\n",
    "        img_name = train_data['img_name']\n",
    "        img_loc = train_data['img_loc']\n",
    "        node_num = train_data['node_num']\n",
    "        roi_labels = train_data['roi_labels']\n",
    "        det_boxes = train_data['det_boxes']\n",
    "        edge_labels = train_data['edge_labels']\n",
    "        edge_num = train_data['edge_num']\n",
    "        features = train_data['features']\n",
    "        spatial_feat = train_data['spatial_feat']\n",
    "        word2vec = train_data['word2vec']\n",
    "        features, spatial_feat, word2vec, edge_labels = features.to(device), spatial_feat.to(device), word2vec.to(device), edge_labels.to(device)    \n",
    "            \n",
    "        #if img_name[0] == 'frame123.jpg':\n",
    "            #print(edge_labels)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(node_num, features, spatial_feat, word2vec, roi_labels, validation=True)\n",
    "            \n",
    "            if args.use_t: outputs/args.t_scale\n",
    "            elif args.use_cda_t: outputs = outputs/temp\n",
    "\n",
    "            logits_list.append(outputs)\n",
    "            labels_list.append(edge_labels)       \n",
    "            \n",
    "            # loss and accuracy\n",
    "            loss = criterion(outputs, edge_labels.float())\n",
    "            acc = np.sum(np.equal(np.argmax(outputs.cpu().data.numpy(), axis=-1), np.argmax(edge_labels.cpu().data.numpy(), axis=-1)))\n",
    "            \n",
    "            #if img_name[0] == 'frame123.jpg' or img_name[0] == 'frame0450.jpg':\n",
    "            #    print(np.argmax(edge_labels.cpu().data.numpy(), axis=-1))\n",
    "            #    print(np.argmax(outputs.cpu().data.numpy(), axis=-1))\n",
    "        # accumulate loss and accuracy of the batch\n",
    "        total_loss += loss.item() * edge_labels.shape[0]\n",
    "        total_acc  += acc\n",
    "        edge_count += edge_labels.shape[0]\n",
    "    \n",
    "    logits_all = torch.cat(logits_list).cuda()\n",
    "    labels_all = torch.cat(labels_list).cuda()\n",
    "    \n",
    "    # calculate the loss and accuracy\n",
    "    total_acc = total_acc / edge_count\n",
    "    total_loss = total_loss / len(val_dataloader)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    logits_all = F.softmax(logits_all, dim=1)\n",
    "    map_value, recall, ece, sce, tace, brier, uce = calibration_metrics(logits_all, labels_all, rdname, plot=plot, model_name=plot_name)\n",
    "    print('acc: %0.6f, map: %0.6f, recall: %0.6f, loss: %0.6f, ece:%0.6f, sce:%0.6f, tace:%0.6f, brier:%.6f, uce:%.6f' %(total_acc, map_value, recall, total_loss, ece, sce, tace, brier, uce.item()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.629630, map: 0.268185, recall: 0.288829, loss: 0.398220, ece:0.088919, sce:0.027499, tace:0.026858, brier:0.549721, uce:0.078510\n",
      "190\n",
      "acc: 0.354949, map: 0.099882, recall: 0.132667, loss: 0.641266, ece:0.159171, sce:0.067803, tace:0.068267, brier:0.817442, uce:0.174625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "arguments\n",
    "    Hyperparameters, file location, optimizer, network, data_processing\n",
    "'''    \n",
    "ver = 'N_d2g_resnet18_09'\n",
    "f_e = 'resnet18_09'\n",
    "\n",
    "class arguments():\n",
    "    def __init__(self):\n",
    "\n",
    "        self.batch_size = 32\n",
    "\n",
    "        # network\n",
    "        self.layers= 1\n",
    "        self.bn = False\n",
    "        self.drop_prob = 0.3\n",
    "        self.bias = True\n",
    "        self.multi_attn = False\n",
    "        self.diff_edge = False\n",
    "\n",
    "        # data_processing\n",
    "        self.sampler = 0\n",
    "        self.data_aug = False\n",
    "        self.feature_extractor = f_e\n",
    "        \n",
    "        # CBS\n",
    "        self.use_cbs = False\n",
    "        \n",
    "        # temperature_scaling\n",
    "        self.use_t = False\n",
    "        self.use_cda_t = False\n",
    "        self.t_scale = 1.5\n",
    "        \n",
    "        self.testset = [1,2]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    seed_everything()\n",
    "    args = arguments()\n",
    "    data_const = SurgicalSceneConstants()\n",
    "    \n",
    "    for domain in args.testset:\n",
    "        # val dataset\n",
    "        if domain == 1:\n",
    "            train_seq = [[2,3,4,6,7,9,10,11,12,14,15]]\n",
    "            val_seq = [[1,5,16]]\n",
    "            data_dir = ['datasets/instruments18/seq_']\n",
    "            img_dir = ['/left_frames/']\n",
    "            dset = [0]\n",
    "            seq = {'train_seq': train_seq, 'val_seq': val_seq, 'data_dir': data_dir, 'img_dir':img_dir, 'dset': dset}\n",
    "\n",
    "        elif domain == 2:\n",
    "            train_seq = [[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]]\n",
    "            val_seq = [[16,17,18,19,20,21,22]]\n",
    "            data_dir = ['datasets/SGH_dataset_2020/']\n",
    "            img_dir = ['/resized_frames/']\n",
    "            dset = [1]\n",
    "            seq = {'train_seq': train_seq, 'val_seq': val_seq, 'data_dir': data_dir, 'img_dir':img_dir, 'dset': dset}\n",
    "\n",
    "        elif domain == 12:\n",
    "            train_seq = [[2,3,4,6,7,9,10,11,12,14,15], [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]]\n",
    "            val_seq = [[1,5,16],[16,17,18,19,20,21,22]]\n",
    "            #val_seq = [[5],[22]]\n",
    "            data_dir = ['datasets/instruments18/seq_', 'datasets/SGH_dataset_2020/']\n",
    "            img_dir = ['/left_frames/', '/resized_frames/']\n",
    "            dset = [0, 1]\n",
    "            seq = {'train_seq': train_seq, 'val_seq': val_seq, 'data_dir': data_dir, 'img_dir':img_dir, 'dset': dset}\n",
    "\n",
    "        # model\n",
    "        model = AGRNN(bias=args.bias, bn=args.bn, dropout=args.drop_prob, multi_attn=args.multi_attn, layer=args.layers, diff_edge=args.diff_edge, use_cbs = args.use_cbs)\n",
    "        if args.use_cbs: model.grnn1.gnn.apply_h_h_edge.get_new_kernels(0)\n",
    "\n",
    "#         for i in [150,160,170,180,190,200,210,220,230,240,250]:\n",
    "        for i in [190]: # 190,190,190,220,190,220\n",
    "#         for i in [20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250]:\n",
    "#         for i in [50]: #50,20,40,80\n",
    "#         for i in [20,30,40,50,60,70,80]:\n",
    "#         for i in [50]:\n",
    "#             pretrain_model = 'checkpoints/'+ver+'/'+ver+'/'+'epoch_train/checkpoint_D2F'+str(i)+'_epoch.pth'\n",
    "            pretrain_model = 'checkpoints/'+ver+'/'+ver+'/'+'epoch_train/checkpoint_D1'+str(i)+'_epoch.pth'\n",
    "#             pretrain_model = 'checkpoints/'+ver+'/'+ver+'/'+'epoch_train/checkpoint_D2'+str(i)+'_epoch.pth'\n",
    "            checkpoints = torch.load(pretrain_model)\n",
    "            model.load_state_dict(checkpoints['state_dict'])\n",
    "\n",
    "            # use cpu or cuda\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            model.to(device)\n",
    "            print(i)\n",
    "            evaluate(args, data_const, model,seq, device, \"D1\", str(i),plot=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.515818 map: 0.289081 loss: 13.722995, ece:0.162411, sce:0.037534, tace:0.037534, brier:0.704601, uce:0.173540\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    for i in [60]:\n",
    "        pretrain_model = 'checkpoints/'+ver+'/'+ver+'/'+'epoch_train/checkpoint_D2F'+str(i)+'_epoch.pth'\n",
    "        checkpoints = torch.load(pretrain_model)\n",
    "        model.load_state_dict(checkpoints['state_dict'])\n",
    "    \n",
    "        # use cpu or cuda\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "    \n",
    "        evaluate(args, data_const, model,seq, device, \"D12\", str(i), plot=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDG:\n",
    "# ver = 'N_d2g_resnet18_09',                i = 190, acc: 0.629630, map: 0.268185, ece:0.088919, acc: 0.354949, map: 0.099882, ece:0.159171\n",
    "# ver = 'N_d2g_resnet18_09_ls',             i = 190, acc: 0.638243, map: 0.264871, ece:0.097475, acc: 0.351536, map: 0.098766, ece:0.170510\n",
    "# ver = 'N_d2g_resnet18_11',                i = 190, acc: 0.635659, map: 0.267275, ece:0.099967, acc: 0.368601, map: 0.101175, ece:0.166661\n",
    "# ver = 'N_d2g_ecbs_resnet18_11_cbs',       i = 220, acc: 0.636520, map: 0.312943, ece:0.092077, acc: 0.412969, map: 0.101176, ece:0.120662\n",
    "# ver = 'N_d2g_t_resnet18_11_ts',           i = 190, acc: 0.645134, map: 0.259435, ece:0.142313, acc: 0.358362, map: 0.096502, ece:0.245330\n",
    "# ver = 'N_d2g_ecbs_t_resnet18_11_cbs_ts',  i = 220, acc: 0.633075, map: 0.297516, ece:0.137914, acc: 0.392491, map: 0.100909, ece:0.214906\n",
    "\n",
    "DG:\n",
    "# ver = 'N_d2g_resnet18_11',                i = 50,  acc: 0.554694, map: 0.307214, ece:0.205270, acc: 0.358362, map: 0.117814, ece:0.176996\n",
    "# ver = 'N_d2g_ecbs_resnet18_11_cbs',       i = 20,  acc: 0.577089, map: 0.286954, ece:0.224620, acc: 0.331058, map: 0.150166, ece:0.190530\n",
    "# ver = 'N_d2g_t_resnet18_11_ts',           i = 40,  acc: 0.548665, map: 0.312332, ece:0.168055, acc: 0.344710, map: 0.106964, ece:0.298148\n",
    "# ver = 'N_d2g_ecbs_t_resnet18_11_cbs_ts',  i = 80,  acc: 0.565891, map: 0.333887, ece:0.173889, acc: 0.331058, map: 0.140739, ece:0.320320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.532325 map: 0.265036 loss: 14.353656, ece:0.200860, sce:0.036920, tace:0.040550, brier:0.687435, uce:0.192916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.523384 map: 0.283751 loss: 13.764285, ece:0.168208, sce:0.039178, tace:0.038381, brier:0.714713, uce:0.173640\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ver = 'd2g_resnet18_11_cbs_ts'\n",
    "# i = 60\n",
    "# pretrain_model = 'checkpoints/'+ver+'/'+ver+'/'+'epoch_train/checkpoint_D2F'+str(i)+'_epoch.pth'\n",
    "# checkpoints = torch.load(pretrain_model)\n",
    "# model1.load_state_dict(checkpoints['state_dict'])\n",
    "    \n",
    "# # use cpu or cuda\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model1.to(device)\n",
    "    \n",
    "# evaluate(args, data_const, model1,seq, device, \"D12\", str(i), plot=True, plot_name = 'Base + FE(11C) + DA') \n",
    "\n",
    "# ver = 'd2g_t_resnet18_11_cbs_ts'\n",
    "# i = 60\n",
    "# pretrain_model = 'checkpoints/'+ver+'/'+ver+'/'+'epoch_train/checkpoint_D2F'+str(i)+'_epoch.pth'\n",
    "# checkpoints = torch.load(pretrain_model)\n",
    "# model2.load_state_dict(checkpoints['state_dict'])\n",
    "    \n",
    "# # use cpu or cuda\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model2.to(device)\n",
    "    \n",
    "# evaluate(args, data_const, model2,seq, device, \"D12\", str(i), plot=True, plot_name = 'Base + FE(11C) + DA + TS') \n",
    "\n",
    "# ver = 'd2g_cbs_resnet18_11_cbs_ts'\n",
    "# i = 80\n",
    "# pretrain_model = 'checkpoints/'+ver+'/'+ver+'/'+'epoch_train/checkpoint_D2F'+str(i)+'_epoch.pth'\n",
    "# checkpoints = torch.load(pretrain_model)\n",
    "# model3.load_state_dict(checkpoints['state_dict'])\n",
    "    \n",
    "# # use cpu or cuda\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model3.to(device)\n",
    "    \n",
    "# evaluate(args, data_const, model3,seq, device, \"D12\", str(i), plot=True, plot_name = 'Base + FE(11C) + DA + CBS') \n",
    "\n",
    "# ver = 'd2g_cbs_t_resnet18_11_cbs_ts'\n",
    "# i = 80\n",
    "# pretrain_model = 'checkpoints/'+ver+'/'+ver+'/'+'epoch_train/checkpoint_D2F'+str(i)+'_epoch.pth'\n",
    "# checkpoints = torch.load(pretrain_model)\n",
    "# model4.load_state_dict(checkpoints['state_dict'])\n",
    "    \n",
    "# # use cpu or cuda\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model4.to(device)\n",
    "    \n",
    "# evaluate(args, data_const, model4,seq, device, \"D12\", str(i), plot=True, plot_name = 'Base + FE(11C) + DA + CBS+ TS') \n",
    "\n",
    "ver = 'd2g_ecbs_resnet18_11_cbs_ts'\n",
    "i = 60\n",
    "pretrain_model = 'checkpoints/'+ver+'/'+ver+'/'+'epoch_train/checkpoint_D2F'+str(i)+'_epoch.pth'\n",
    "checkpoints = torch.load(pretrain_model)\n",
    "model5.load_state_dict(checkpoints['state_dict'])\n",
    "    \n",
    "# use cpu or cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model5.to(device)\n",
    "    \n",
    "evaluate(args, data_const, model5,seq, device, \"D12\", str(i), plot=True, plot_name = 'Base + FE(11C) + DA + E-CBS') \n",
    "\n",
    "ver = 'd2g_ecbs_t_resnet18_11_cbs_ts'\n",
    "i = 70\n",
    "pretrain_model = 'checkpoints/'+ver+'/'+ver+'/'+'epoch_train/checkpoint_D2F'+str(i)+'_epoch.pth'\n",
    "checkpoints = torch.load(pretrain_model)\n",
    "model6.load_state_dict(checkpoints['state_dict'])\n",
    "    \n",
    "# use cpu or cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model6.to(device)\n",
    "    \n",
    "evaluate(args, data_const, model6,seq, device, \"D12\", str(i), plot=True, plot_name = 'Base + FE(11C) + DA + E-CBS + TS') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
