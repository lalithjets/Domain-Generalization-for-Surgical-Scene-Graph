{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "configurations of the network\n",
    "    \n",
    "    readout: G_ER_L_S = [1024+300+16+300+1024,  1024, 117]\n",
    "\n",
    "    node_func: G_N_L_S = [1024+1024, 1024]\n",
    "    node_lang_func: G_N_L_S2 = [300+300+300]\n",
    "    \n",
    "    edge_func : G_E_L_S = [1024*2+16, 1024]\n",
    "    edge_lang_func: [300*2, 1024]\n",
    "    \n",
    "    attn: [1024, 1]\n",
    "    attn_lang: [1024, 1]\n",
    "'''\n",
    "\n",
    "class CONFIGURATION(object):\n",
    "    '''\n",
    "    Configuration arguments: feature type, layer, bias, batch normalization, dropout, multi-attn\n",
    "    \n",
    "    readout           : fc_size, activation, bias, bn, droupout\n",
    "    gnn_node          : fc_size, activation, bias, bn, droupout\n",
    "    gnn_node_for_lang : fc_size, activation, bias, bn, droupout\n",
    "    gnn_edge          : fc_size, activation, bias, bn, droupout\n",
    "    gnn_edge_for_lang : fc_size, activation, bias, bn, droupout\n",
    "    gnn_attn          : fc_size, activation, bias, bn, droupout\n",
    "    gnn_attn_for_lang : fc_size, activation, bias, bn, droupout\n",
    "    '''\n",
    "    def __init__(self, layer=1, bias=True, bn=False, dropout=0.2, multi_attn=False):\n",
    "        \n",
    "        # if multi_attn:\n",
    "        if True:\n",
    "            if layer==1:\n",
    "                feature_size = 512\n",
    "                # readout\n",
    "                self.G_ER_L_S = [feature_size+300+16+300+feature_size, feature_size, 13]\n",
    "                self.G_ER_A   = ['ReLU', 'Identity']\n",
    "                self.G_ER_B   = bias    #true\n",
    "                self.G_ER_BN  = bn      #false\n",
    "                self.G_ER_D   = dropout #0.3\n",
    "                # self.G_ER_GRU = feature_size\n",
    "\n",
    "                # # gnn node function\n",
    "                self.G_N_L_S = [feature_size+feature_size, feature_size]\n",
    "                self.G_N_A   = ['ReLU']\n",
    "                self.G_N_B   = bias #true\n",
    "                self.G_N_BN  = bn      #false\n",
    "                self.G_N_D   = dropout #0.3\n",
    "                # self.G_N_GRU = feature_size\n",
    "\n",
    "                # # gnn node function for language\n",
    "                self.G_N_L_S2 = [300+300, 300]\n",
    "                self.G_N_A2   = ['ReLU']\n",
    "                self.G_N_B2   = bias    #true\n",
    "                self.G_N_BN2  = bn      #false\n",
    "                self.G_N_D2   = dropout #0.3\n",
    "                # self.G_N_GRU2 = feature_size\n",
    "\n",
    "                # gnn edge function1\n",
    "                self.G_E_L_S           = [feature_size*2+16, feature_size]\n",
    "                self.G_E_A             = ['ReLU']\n",
    "                self.G_E_B             = bias     # true\n",
    "                self.G_E_BN            = bn       # false\n",
    "                self.G_E_D             = dropout  # 0.3\n",
    "                self.G_E_c_std         = 1.0\n",
    "                self.G_E_c_std_factor  = 0.9      # 0.985 (LOG), 0.95 (gau)\n",
    "                self.G_E_c_epoch       = 20\n",
    "                self.G_E_c_kernel_size = 3\n",
    "                self.G_E_c_filter      = 'LOG' # 'gau', 'LOG'\n",
    "\n",
    "                # gnn edge function2 for language\n",
    "                self.G_E_L_S2 = [300*2, feature_size]\n",
    "                self.G_E_A2   = ['ReLU']\n",
    "                self.G_E_B2   = bias     #true\n",
    "                self.G_E_BN2  = bn       #false\n",
    "                self.G_E_D2   = dropout  #0.3\n",
    "\n",
    "                # gnn attention mechanism\n",
    "                self.G_A_L_S = [feature_size, 1]\n",
    "                self.G_A_A   = ['LeakyReLU']\n",
    "                self.G_A_B   = bias     #true\n",
    "                self.G_A_BN  = bn       #false\n",
    "                self.G_A_D   = dropout  #0.3\n",
    "\n",
    "                # gnn attention mechanism2 for language\n",
    "                self.G_A_L_S2 = [feature_size, 1]\n",
    "                self.G_A_A2   = ['LeakyReLU']\n",
    "                self.G_A_B2   = bias    #true\n",
    "                self.G_A_BN2  = bn      #false\n",
    "                self.G_A_D2   = dropout #0.3\n",
    "                    \n",
    "    def save_config(self):\n",
    "        model_config = {'graph_head':{}, 'graph_node':{}, 'graph_edge':{}, 'graph_attn':{}}\n",
    "        CONFIG=self.__dict__\n",
    "        for k, v in CONFIG.items():\n",
    "            if 'G_H' in k:\n",
    "                model_config['graph_head'][k]=v\n",
    "            elif 'G_N' in k:\n",
    "                model_config['graph_node'][k]=v\n",
    "            elif 'G_E' in k:\n",
    "                model_config['graph_edge'][k]=v\n",
    "            elif 'G_A' in k:\n",
    "                model_config['graph_attn'][k]=v\n",
    "            else:\n",
    "                model_config[k]=v\n",
    "        \n",
    "        return model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def get_gaussian_filter_1D(kernel_size=3, sigma=2, channels=3):\n",
    "    # Create a x, y coordinate grid of shape (kernel_size, kernel_size, 2)\n",
    "    \n",
    "    x_coord = torch.arange(kernel_size)\n",
    "    x_grid = x_coord.repeat(kernel_size).view(kernel_size, kernel_size)\n",
    "    y_grid = x_grid.t()\n",
    "\n",
    "    xy_grid = torch.stack([x_grid, y_grid], dim=-1).float()\n",
    "    mean = (kernel_size - 1)/2.\n",
    "    variance = sigma**2.\n",
    "    xy_grid = torch.sum((xy_grid[:kernel_size,:kernel_size,:] - mean)**2., dim=-1)\n",
    "\n",
    "    # Calculate the 1-dimensional gaussian kernel\n",
    "    gaussian_kernel = (1./((math.sqrt(2.*math.pi)*sigma))) * \\\n",
    "                        torch.exp(-1* (xy_grid[int(kernel_size/2)]) / (2*variance))\n",
    "\n",
    "    gaussian_kernel = gaussian_kernel / torch.sum(gaussian_kernel)\n",
    "    gaussian_kernel = gaussian_kernel.view(1, 1, kernel_size)\n",
    "    gaussian_kernel = gaussian_kernel.repeat(channels, 1, 1)\n",
    "\n",
    "    padding = 1 if kernel_size==3 else 2 if kernel_size == 5 else 0\n",
    "    gaussian_filter = nn.Conv1d(in_channels=channels, out_channels=channels,\n",
    "                                kernel_size=kernel_size, groups=channels,\n",
    "                                bias=False, padding=padding)\n",
    "    gaussian_filter.weight.data = gaussian_kernel\n",
    "    gaussian_filter.weight.requires_grad = False \n",
    "    return gaussian_filter\n",
    "\n",
    "def get_laplaceOfGaussian_filter_1D(kernel_size=3, sigma=2, channels=3):\n",
    "    \n",
    "    # Create a x, y coordinate grid of shape (kernel_size, kernel_size, 2)\n",
    "    x_coord = torch.arange(kernel_size)\n",
    "    x_grid = x_coord.repeat(kernel_size).view(kernel_size, kernel_size)\n",
    "    y_grid = x_grid.t()\n",
    "    xy_grid = torch.stack([x_grid, y_grid], dim=-1).float()\n",
    "    mean = (kernel_size - 1)/2.\n",
    "\n",
    "    used_sigma = sigma\n",
    "    # Calculate the 2-dimensional gaussian kernel which is\n",
    "    log_kernel = (-1./(math.pi*(used_sigma**4))) \\\n",
    "                  * (1-(torch.sum((xy_grid[int(kernel_size/2)] - mean)**2., dim=-1) / (2*(used_sigma**2)))) \\\n",
    "                  * torch.exp(-torch.sum((xy_grid[int(kernel_size/2)] - mean)**2., dim=-1) / (2*(used_sigma**2)))\n",
    "    \n",
    "    # Make sure sum of values in gaussian kernel equals 1.\n",
    "    log_kernel = log_kernel / torch.sum(log_kernel)\n",
    "    log_kernel = log_kernel.view(1, 1, kernel_size)\n",
    "    log_kernel = log_kernel.repeat(channels, 1, 1)\n",
    "\n",
    "    padding = 1 if kernel_size==3 else 2 if kernel_size == 5 else 0\n",
    "    log_filter = nn.Conv1d(in_channels=channels, out_channels=channels,\n",
    "                                kernel_size=kernel_size, groups=channels,\n",
    "                                bias=False, padding=padding)\n",
    "    log_filter.weight.data = log_kernel\n",
    "    log_filter.weight.requires_grad = False\n",
    "    return log_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Primary activation and MLP layer\n",
    "acivation:\n",
    "    Identity\n",
    "    ReLU\n",
    "    LeakyReLU\n",
    "MLP:\n",
    "    init: layer size, activation, bias, use_BN, dropout_probability\n",
    "    forward: x\n",
    "'''\n",
    "\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    '''\n",
    "    Identity class activation layer\n",
    "    x = x\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Identity,self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "def get_activation(name):\n",
    "    '''\n",
    "    get_activation sub-function\n",
    "    argument: activatoin name (eg. ReLU, Identity, LeakyReLU)\n",
    "    '''\n",
    "    if name=='ReLU': return nn.ReLU(inplace=True)\n",
    "    elif name=='Identity': return Identity()\n",
    "    elif name=='LeakyReLU': return nn.LeakyReLU(0.2,inplace=True)\n",
    "    else: assert(False), 'Not Implemented'\n",
    "    #elif name=='Tanh': return nn.Tanh()\n",
    "    #elif name=='Sigmoid': return nn.Sigmoid()\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    '''\n",
    "    Args:\n",
    "        layer_sizes: a list, [1024,1024,...]\n",
    "        activation: a list, ['ReLU', 'Tanh',...]\n",
    "        bias : bool\n",
    "        use_bn: bool\n",
    "        drop_prob: default is None, use drop out layer or not\n",
    "    '''\n",
    "    def __init__(self, layer_sizes, activation, bias=True, use_bn=False, drop_prob=None):\n",
    "        super(MLP, self).__init__()\n",
    "        self.bn = use_bn\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            layer = nn.Linear(layer_sizes[i], layer_sizes[i+1], bias=bias)\n",
    "            activate = get_activation(activation[i])\n",
    "            block = nn.Sequential(OrderedDict([(f'L{i}', layer), ]))\n",
    "            \n",
    "            # !NOTE:# Actually, it is inappropriate to use batch-normalization here\n",
    "            if use_bn:                                  \n",
    "                bn = nn.BatchNorm1d(layer_sizes[i+1])\n",
    "                block.add_module(f'B{i}', bn)\n",
    "            \n",
    "            # batch normalization is put before activation function \n",
    "            block.add_module(f'A{i}', activate)\n",
    "\n",
    "            # dropout probablility\n",
    "            if drop_prob:\n",
    "                block.add_module(f'D{i}', nn.Dropout(drop_prob))\n",
    "            \n",
    "            self.layers.append(block)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # !NOTE: sometime the shape of x will be [1,N], and we cannot use batch-normailzation in that situation\n",
    "            if self.bn and x.shape[0]==1:\n",
    "                x = layer[0](x)\n",
    "                x = layer[:-1](x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "H_H_EdgeApplyModule\n",
    "    init    : config, multi_attn \n",
    "    forward : edge\n",
    "    \n",
    "H_NodeApplyModule\n",
    "    init    : config\n",
    "    forward : node\n",
    "    \n",
    "E_AttentionModule1\n",
    "    init    : config\n",
    "    forward : edge\n",
    "    \n",
    "GNN\n",
    "    init    : config, multi_attn, diff_edge\n",
    "    forward : g, h_node, o_node, h_h_e_list, o_o_e_list, h_o_e_list, pop_features\n",
    "    \n",
    "GRNN\n",
    "    init    : config, multi_attn, diff_edge\n",
    "    forward : b_graph, b_h_node_list, b_o_node_list, b_h_h_e_list, b_o_o_e_list, b_h_o_e_list, features, spatial_features, word2vec, valid, pop_features, initial_features\n",
    "'''\n",
    "\n",
    "import ipdb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class H_H_EdgeApplyModule(nn.Module): #human to human edge\n",
    "    '''\n",
    "        init    : config, multi_attn \n",
    "        forward : edge\n",
    "    '''\n",
    "    def __init__(self, CONFIG, multi_attn=False, use_cbs = False):\n",
    "        super(H_H_EdgeApplyModule, self).__init__()\n",
    "        self.use_cbs = use_cbs\n",
    "        if use_cbs:\n",
    "            self.init_std = CONFIG.G_E_c_std \n",
    "            self.cbs_std = CONFIG.G_E_c_std\n",
    "            self.cbs_std_factor = CONFIG.G_E_c_std_factor\n",
    "            self.cbs_epoch = CONFIG.G_E_c_epoch\n",
    "            self.cbs_kernel_size = CONFIG.G_E_c_kernel_size\n",
    "            self.cbs_filter = CONFIG.G_E_c_filter\n",
    "        \n",
    "        self.edge_fc = MLP(CONFIG.G_E_L_S, CONFIG.G_E_A, CONFIG.G_E_B, CONFIG.G_E_BN, CONFIG.G_E_D)\n",
    "        self.edge_fc_lang = MLP(CONFIG.G_E_L_S2, CONFIG.G_E_A2, CONFIG.G_E_B2, CONFIG.G_E_BN2, CONFIG.G_E_D2)\n",
    "    \n",
    "    def forward(self, edge):\n",
    "        feat = torch.cat([edge.src['n_f'], edge.data['s_f'], edge.dst['n_f']], dim=1)\n",
    "        feat_lang = torch.cat([edge.src['word2vec'], edge.dst['word2vec']], dim=1)\n",
    "        if self.use_cbs:\n",
    "            feat = self.kernel1(feat[:,None,:])\n",
    "            feat = torch.squeeze(feat, 1)\n",
    "        e_feat = self.edge_fc(feat)\n",
    "        e_feat_lang = self.edge_fc_lang(feat_lang)\n",
    "  \n",
    "        return {'e_f': e_feat, 'e_f_lang': e_feat_lang}\n",
    "\n",
    "    def get_new_kernels(self, epoch_count):\n",
    "        if self.use_cbs:\n",
    "            if epoch_count == 0:\n",
    "                self.cbs_std = self.init_std\n",
    "                \n",
    "            if epoch_count % self.cbs_epoch == 0 and epoch_count is not 0:\n",
    "                self.cbs_std *= self.cbs_std_factor\n",
    "            \n",
    "            if (self.cbs_filter == 'gau'): \n",
    "                self.kernel1 = get_gaussian_filter_1D(kernel_size=self.cbs_kernel_size, sigma= self.cbs_std, channels= 1)\n",
    "            elif (self.cbs_filter == 'LOG'): \n",
    "                self.kernel1 = get_laplaceOfGaussian_filter_1D(kernel_size=self.cbs_kernel_size, sigma= self.cbs_std, channels= 1)\n",
    "\n",
    "class H_NodeApplyModule(nn.Module): #human node\n",
    "    '''\n",
    "        init    : config\n",
    "        forward : node\n",
    "    '''\n",
    "    def __init__(self, CONFIG):\n",
    "        super(H_NodeApplyModule, self).__init__()\n",
    "        self.node_fc = MLP(CONFIG.G_N_L_S, CONFIG.G_N_A, CONFIG.G_N_B, CONFIG.G_N_BN, CONFIG.G_N_D)\n",
    "        self.node_fc_lang = MLP(CONFIG.G_N_L_S2, CONFIG.G_N_A2, CONFIG.G_N_B2, CONFIG.G_N_BN2, CONFIG.G_N_D2)\n",
    "    \n",
    "    def forward(self, node):\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        feat = torch.cat([node.data['n_f'], node.data['z_f']], dim=1)\n",
    "        feat_lang = torch.cat([node.data['word2vec'], node.data['z_f_lang']], dim=1)\n",
    "        n_feat = self.node_fc(feat)\n",
    "        n_feat_lang = self.node_fc_lang(feat_lang)\n",
    "\n",
    "        return {'new_n_f': n_feat, 'new_n_f_lang': n_feat_lang}\n",
    "\n",
    "class E_AttentionModule1(nn.Module): #edge attention\n",
    "    '''\n",
    "        init    : config\n",
    "        forward : edge\n",
    "    '''\n",
    "    def __init__(self, CONFIG):\n",
    "        super(E_AttentionModule1, self).__init__()\n",
    "        self.attn_fc = MLP(CONFIG.G_A_L_S, CONFIG.G_A_A, CONFIG.G_A_B, CONFIG.G_A_BN, CONFIG.G_A_D)\n",
    "        self.attn_fc_lang = MLP(CONFIG.G_A_L_S2, CONFIG.G_A_A2, CONFIG.G_A_B2, CONFIG.G_A_BN2, CONFIG.G_A_D2)\n",
    "\n",
    "    def forward(self, edge):\n",
    "        a_feat = self.attn_fc(edge.data['e_f'])\n",
    "        a_feat_lang = self.attn_fc_lang(edge.data['e_f_lang'])\n",
    "        return {'a_feat': a_feat, 'a_feat_lang': a_feat_lang}\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    '''\n",
    "        init    : config, multi_attn, diff_edge\n",
    "        forward : g, h_node, o_node, h_h_e_list, o_o_e_list, h_o_e_list, pop_features\n",
    "    '''\n",
    "    def __init__(self, CONFIG, multi_attn=False, diff_edge=True, use_cbs = False):\n",
    "        super(GNN, self).__init__()\n",
    "        self.diff_edge = diff_edge # false\n",
    "        self.apply_h_h_edge = H_H_EdgeApplyModule(CONFIG, multi_attn, use_cbs)\n",
    "        self.apply_edge_attn1 = E_AttentionModule1(CONFIG)  \n",
    "        self.apply_h_node = H_NodeApplyModule(CONFIG)\n",
    "\n",
    "    def _message_func(self, edges):\n",
    "        return {'nei_n_f': edges.src['n_f'], 'nei_n_w': edges.src['word2vec'], 'e_f': edges.data['e_f'], 'e_f_lang': edges.data['e_f_lang'], 'a_feat': edges.data['a_feat'], 'a_feat_lang': edges.data['a_feat_lang']}\n",
    "\n",
    "    def _reduce_func(self, nodes):\n",
    "        alpha = F.softmax(nodes.mailbox['a_feat'], dim=1)\n",
    "        alpha_lang = F.softmax(nodes.mailbox['a_feat_lang'], dim=1)\n",
    "\n",
    "        z_raw_f = nodes.mailbox['nei_n_f']+nodes.mailbox['e_f']\n",
    "        z_f = torch.sum( alpha * z_raw_f, dim=1)\n",
    "\n",
    "        z_raw_f_lang = nodes.mailbox['nei_n_w']\n",
    "        z_f_lang = torch.sum(alpha_lang * z_raw_f_lang, dim=1)\n",
    "         \n",
    "        # we cannot return 'alpha' for the different dimension \n",
    "        if self.training or validation: return {'z_f': z_f, 'z_f_lang': z_f_lang}\n",
    "        else: return {'z_f': z_f, 'z_f_lang': z_f_lang, 'alpha': alpha, 'alpha_lang': alpha_lang}\n",
    "\n",
    "    def forward(self, g, h_node, o_node, h_h_e_list, o_o_e_list, h_o_e_list, pop_feat=False):\n",
    "        \n",
    "        g.apply_edges(self.apply_h_h_edge, g.edges())\n",
    "        g.apply_edges(self.apply_edge_attn1)\n",
    "        g.update_all(self._message_func, self._reduce_func)\n",
    "        g.apply_nodes(self.apply_h_node, h_node+o_node)\n",
    "\n",
    "        # !NOTE:PAY ATTENTION WHEN ADDING MORE FEATURE\n",
    "        g.ndata.pop('n_f')\n",
    "        g.ndata.pop('word2vec')\n",
    "\n",
    "        g.ndata.pop('z_f')\n",
    "        g.edata.pop('e_f')\n",
    "        g.edata.pop('a_feat')\n",
    "\n",
    "        g.ndata.pop('z_f_lang')\n",
    "        g.edata.pop('e_f_lang')\n",
    "        g.edata.pop('a_feat_lang')\n",
    "\n",
    "class GRNN(nn.Module):\n",
    "    '''\n",
    "    init: \n",
    "        config, multi_attn, diff_edge\n",
    "    forward: \n",
    "        batch_graph, batch_h_node_list, batch_obj_node_list,\n",
    "        batch_h_h_e_list, batch_o_o_e_list, batch_h_o_e_list,\n",
    "        features, spatial_features, word2vec,\n",
    "        valid, pop_features, initial_features\n",
    "    '''\n",
    "    def __init__(self, CONFIG, multi_attn=False, diff_edge=True, use_cbs = False):\n",
    "        super(GRNN, self).__init__()\n",
    "        self.multi_attn = multi_attn #false\n",
    "        self.gnn = GNN(CONFIG, multi_attn, diff_edge, use_cbs)\n",
    "\n",
    "    def forward(self, batch_graph, batch_h_node_list, batch_obj_node_list, batch_h_h_e_list, batch_o_o_e_list, batch_h_o_e_list, feat, spatial_feat, word2vec, valid=False, pop_feat=False, initial_feat=False):\n",
    "        \n",
    "        # !NOTE: if node_num==1, there will be something wrong to forward the attention mechanism\n",
    "        global validation \n",
    "        validation = valid\n",
    "\n",
    "        # initialize the graph with some datas\n",
    "        batch_graph.ndata['n_f'] = feat           # node: features \n",
    "        batch_graph.ndata['word2vec'] = word2vec  # node: words\n",
    "        batch_graph.edata['s_f'] = spatial_feat   # edge: spatial features\n",
    "\n",
    "        try:\n",
    "            self.gnn(batch_graph, batch_h_node_list, batch_obj_node_list, batch_h_h_e_list, batch_o_o_e_list, batch_h_o_e_list)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            ipdb.set_trace()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Predictor \n",
    "    init    : config\n",
    "    forward : edge\n",
    "\n",
    "AGRNN\n",
    "    init    : bias, bn, dropout, multi_attn, layer, diff_edge\n",
    "    forward : node_num, feat, spatial_feat, word2vec, roi_label, validation, choose_nodes, remove_nodes\n",
    "'''\n",
    "\n",
    "import dgl\n",
    "import ipdb\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torchvision\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    '''\n",
    "    init    : config\n",
    "    forward : edge\n",
    "    '''\n",
    "    def __init__(self, CONFIG):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.classifier = MLP(CONFIG.G_ER_L_S, CONFIG.G_ER_A, CONFIG.G_ER_B, CONFIG.G_ER_BN, CONFIG.G_ER_D)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, edge):\n",
    "        feat = torch.cat([edge.dst['new_n_f'], edge.dst['new_n_f_lang'], edge.data['s_f'], edge.src['new_n_f_lang'], edge.src['new_n_f']], dim=1)\n",
    "        pred = self.classifier(feat)\n",
    "        # if the criterion is BCELoss, you need to uncomment the following code\n",
    "        # output = self.sigmoid(output)\n",
    "        return {'pred': pred}\n",
    "\n",
    "class AGRNN(nn.Module):\n",
    "    '''\n",
    "    init    : \n",
    "        feature_type, bias, bn, dropout, multi_attn, layer, diff_edge\n",
    "        \n",
    "    forward : \n",
    "        node_num, features, spatial_features, word2vec, roi_label,\n",
    "        validation, choose_nodes, remove_nodes\n",
    "    '''\n",
    "    def __init__(self, bias=True, bn=True, dropout=None, multi_attn=False, layer=1, diff_edge=True, use_cbs = False):\n",
    "        super(AGRNN, self).__init__()\n",
    " \n",
    "        self.multi_attn = multi_attn # false\n",
    "        self.layer = layer           # 1 layer\n",
    "        self.diff_edge = diff_edge   # false\n",
    "        \n",
    "        self.CONFIG1 = CONFIGURATION(layer=1, bias=bias, bn=bn, dropout=dropout, multi_attn=multi_attn)\n",
    "\n",
    "        self.grnn1 = GRNN(self.CONFIG1, multi_attn=multi_attn, diff_edge=diff_edge, use_cbs = use_cbs)\n",
    "        self.edge_readout = Predictor(self.CONFIG1)\n",
    "        \n",
    "    def _collect_edge(self, node_num, roi_label, node_space, diff_edge):\n",
    "        '''\n",
    "        arguments: node_num, roi_label, node_space, diff_edge\n",
    "        '''\n",
    "        \n",
    "        # get human nodes && object nodes\n",
    "        h_node_list = np.where(roi_label == 0)[0]\n",
    "        obj_node_list = np.where(roi_label != 0)[0]\n",
    "        edge_list = []\n",
    "        \n",
    "        h_h_e_list = []\n",
    "        o_o_e_list = []\n",
    "        h_o_e_list = []\n",
    "        \n",
    "        readout_edge_list = []\n",
    "        readout_h_h_e_list = []\n",
    "        readout_h_o_e_list = []\n",
    "        \n",
    "        # get all edge in the fully-connected graph, edge_list, For node_num = 2, edge_list = [(0, 1), (1, 0)]\n",
    "        for src in range(node_num):\n",
    "            for dst in range(node_num):\n",
    "                if src == dst:\n",
    "                    continue\n",
    "                else:\n",
    "                    edge_list.append((src, dst))\n",
    "        \n",
    "        # readout_edge_list, get corresponding readout edge in the graph\n",
    "        src_box_list = np.arange(roi_label.shape[0])\n",
    "        for dst in h_node_list:\n",
    "            # if dst == roi_label.shape[0]-1:\n",
    "            #    continue\n",
    "            # src_box_list = src_box_list[1:]\n",
    "            for src in src_box_list:\n",
    "                if src not in h_node_list:\n",
    "                    readout_edge_list.append((src, dst))\n",
    "        \n",
    "        # readout h_h_e_list, get corresponding readout h_h edges && h_o edges\n",
    "        temp_h_node_list = h_node_list[:]\n",
    "        for dst in h_node_list:\n",
    "            if dst == h_node_list.shape[0]-1:\n",
    "                continue\n",
    "            temp_h_node_list = temp_h_node_list[1:]\n",
    "            for src in temp_h_node_list:\n",
    "                if src == dst: continue\n",
    "                readout_h_h_e_list.append((src, dst))\n",
    "\n",
    "        # readout h_o_e_list\n",
    "        readout_h_o_e_list = [x for x in readout_edge_list if x not in readout_h_h_e_list]\n",
    "\n",
    "        # add node space to match the batch graph\n",
    "        h_node_list = (np.array(h_node_list)+node_space).tolist()\n",
    "        obj_node_list = (np.array(obj_node_list)+node_space).tolist()\n",
    "        \n",
    "        h_h_e_list = (np.array(h_h_e_list)+node_space).tolist() #empty no diff_edge\n",
    "        o_o_e_list = (np.array(o_o_e_list)+node_space).tolist() #empty no diff_edge\n",
    "        h_o_e_list = (np.array(h_o_e_list)+node_space).tolist() #empty no diff_edge\n",
    "\n",
    "        readout_h_h_e_list = (np.array(readout_h_h_e_list)+node_space).tolist()\n",
    "        readout_h_o_e_list = (np.array(readout_h_o_e_list)+node_space).tolist()   \n",
    "        readout_edge_list = (np.array(readout_edge_list)+node_space).tolist()\n",
    "\n",
    "        return edge_list, h_node_list, obj_node_list, h_h_e_list, o_o_e_list, h_o_e_list, readout_edge_list, readout_h_h_e_list, readout_h_o_e_list\n",
    "    \n",
    "    def _build_graph(self, node_num, roi_label, node_space, diff_edge):\n",
    "        '''\n",
    "        Declare graph, add_nodes, collect edges, add_edges\n",
    "        '''\n",
    "        graph = dgl.DGLGraph()\n",
    "        graph.add_nodes(node_num)\n",
    "\n",
    "        edge_list, h_node_list, obj_node_list, h_h_e_list, o_o_e_list, h_o_e_list, readout_edge_list, readout_h_h_e_list, readout_h_o_e_list = self._collect_edge(node_num, roi_label, node_space, diff_edge)\n",
    "        src, dst = tuple(zip(*edge_list))\n",
    "        graph.add_edges(src, dst)   # make the graph bi-directional\n",
    "\n",
    "        return graph, h_node_list, obj_node_list, h_h_e_list, o_o_e_list, h_o_e_list, readout_edge_list, readout_h_h_e_list, readout_h_o_e_list\n",
    "\n",
    "    def forward(self, node_num=None, feat=None, spatial_feat=None, word2vec=None, roi_label=None, validation=False, choose_nodes=None, remove_nodes=None):\n",
    "        \n",
    "        batch_graph, batch_h_node_list, batch_obj_node_list, batch_h_h_e_list, batch_o_o_e_list, batch_h_o_e_list, batch_readout_edge_list, batch_readout_h_h_e_list, batch_readout_h_o_e_list = [], [], [], [], [], [], [], [], []\n",
    "        node_num_cum = np.cumsum(node_num) # !IMPORTANT\n",
    "        \n",
    "        for i in range(len(node_num)):\n",
    "            # set node space\n",
    "            node_space = 0\n",
    "            if i != 0:\n",
    "                node_space = node_num_cum[i-1]\n",
    "            graph, h_node_list, obj_node_list, h_h_e_list, o_o_e_list, h_o_e_list, readout_edge_list, readout_h_h_e_list, readout_h_o_e_list = self._build_graph(node_num[i], roi_label[i], node_space, diff_edge=self.diff_edge)\n",
    "            \n",
    "            # updata batch\n",
    "            batch_graph.append(graph)\n",
    "            batch_h_node_list += h_node_list\n",
    "            batch_obj_node_list += obj_node_list\n",
    "            \n",
    "            batch_h_h_e_list += h_h_e_list\n",
    "            batch_o_o_e_list += o_o_e_list\n",
    "            batch_h_o_e_list += h_o_e_list\n",
    "            \n",
    "            batch_readout_edge_list += readout_edge_list\n",
    "            batch_readout_h_h_e_list += readout_h_h_e_list\n",
    "            batch_readout_h_o_e_list += readout_h_o_e_list\n",
    "        \n",
    "        batch_graph = dgl.batch(batch_graph)\n",
    "        \n",
    "        # GRNN\n",
    "        self.grnn1(batch_graph, batch_h_node_list, batch_obj_node_list, batch_h_h_e_list, batch_o_o_e_list, batch_h_o_e_list, feat, spatial_feat, word2vec, validation, initial_feat=True)\n",
    "        batch_graph.apply_edges(self.edge_readout, tuple(zip(*(batch_readout_h_o_e_list+batch_readout_h_h_e_list))))\n",
    "        \n",
    "        if self.training or validation:\n",
    "            # !NOTE: cannot use \"batch_readout_h_o_e_list+batch_readout_h_h_e_list\" because of the wrong order\n",
    "            return batch_graph.edges[tuple(zip(*batch_readout_edge_list))].data['pred']\n",
    "        else:\n",
    "            return batch_graph.edges[tuple(zip(*batch_readout_edge_list))].data['pred'], \\\n",
    "                   batch_graph.nodes[batch_h_node_list].data['alpha'], \\\n",
    "                   batch_graph.nodes[batch_h_node_list].data['alpha_lang'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils.io as io\n",
    "\n",
    "class SurgicalSceneConstants():\n",
    "    def __init__( self):\n",
    "        self.instrument_classes = ('kidney', 'bipolar_forceps', 'prograsp_forceps', 'large_needle_driver',\n",
    "                      'monopolar_curved_scissors', 'ultrasound_probe', 'suction', 'clip_applier',\n",
    "                      'stapler', 'maryland_dissector', 'spatulated_monopolar_cautery')\n",
    "        \n",
    "        #self.instrument_classes = ( 'kidney', 'bipolar_forceps', 'fenestrated_bipolar', \n",
    "        #                             'prograsp_forceps', 'large_needle_driver', 'vessel_sealer',\n",
    "        #                             'grasping_retractor', 'monopolar_curved_scissors', \n",
    "        #                             'ultrasound_probe', 'suction', 'clip_applier', 'stapler')\n",
    "        \n",
    "        self.action_classes = ( 'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation', \n",
    "                                'Tool_Manipulation', 'Cutting', 'Cauterization', \n",
    "                                'Suction', 'Looping', 'Suturing', 'Clipping', 'Staple', \n",
    "                                'Ultrasound_Sensing')\n",
    "        self.xml_data_dir = 'datasets/instruments18/seq_'\n",
    "        self.word2vec_loc = 'datasets/surgicalscene_word2vec.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "    \n",
    "class SurgicalSceneDataset(Dataset):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self, seq_set, data_dir, img_dir, dset, dataconst, feature_extractor, reduce_size = False):\n",
    "        \n",
    "        \n",
    "        self.data_size = 143\n",
    "        self.dataconst = dataconst\n",
    "        self.img_dir = img_dir\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.reduce_size = reduce_size\n",
    "        \n",
    "        self.xml_dir_list = []\n",
    "        self.dset = []\n",
    "        \n",
    "        for domain in range(len(seq_set)):\n",
    "            domain_dir_list = []\n",
    "            for i in seq_set[domain]:\n",
    "                xml_dir_temp = data_dir[domain] + str(i) + '/xml/'\n",
    "                domain_dir_list = domain_dir_list + glob(xml_dir_temp + '/*.xml')\n",
    "            if self.reduce_size:\n",
    "                indices = np.random.permutation(len(domain_dir_list))\n",
    "                domain_dir_list = [domain_dir_list[j] for j in indices[0:self.data_size]]\n",
    "            for file in domain_dir_list: \n",
    "                self.xml_dir_list.append(file)\n",
    "                self.dset.append(dset[domain])\n",
    "        self.word2vec = h5py.File('datasets/surgicalscene_word2vec.hdf5', 'r')\n",
    "    \n",
    "    # word2vec\n",
    "    def _get_word2vec(self,node_ids, sgh = 0):\n",
    "        word2vec = np.empty((0,300))\n",
    "        for node_id in node_ids:\n",
    "            if sgh == 1 and node_id == 0:\n",
    "                vec = self.word2vec['tissue']\n",
    "            else:\n",
    "                vec = self.word2vec[self.dataconst.instrument_classes[node_id]]\n",
    "            word2vec = np.vstack((word2vec, vec))\n",
    "        return word2vec\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xml_dir_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "    \n",
    "        file_name = os.path.splitext(os.path.basename(self.xml_dir_list[idx]))[0]\n",
    "        file_root = os.path.dirname(os.path.dirname(self.xml_dir_list[idx]))\n",
    "        if len(self.img_dir) == 1:\n",
    "            _img_loc = os.path.join(file_root+self.img_dir[0]+ file_name + '.png')\n",
    "        else:\n",
    "            _img_loc = os.path.join(file_root+self.img_dir[self.dset[idx]]+ file_name + '.png')\n",
    "        frame_data = h5py.File(os.path.join(file_root+'/vsgat/'+self.feature_extractor+'/'+ file_name + '_features.hdf5'), 'r')    \n",
    "        data = {}\n",
    "        data['img_name'] = frame_data['img_name'].value[:] + '.jpg'\n",
    "        data['img_loc'] = _img_loc\n",
    "        \n",
    "        data['node_num'] = frame_data['node_num'].value\n",
    "        data['roi_labels'] = frame_data['classes'][:]\n",
    "        data['det_boxes'] = frame_data['boxes'][:]\n",
    "        \n",
    "        \n",
    "        data['edge_labels'] = frame_data['edge_labels'][:]\n",
    "        data['edge_num'] = data['edge_labels'].shape[0]\n",
    "        \n",
    "        data['features'] = frame_data['node_features'][:]\n",
    "        data['spatial_feat'] = frame_data['spatial_features'][:]\n",
    "        \n",
    "        \n",
    "        data['word2vec'] = self._get_word2vec(data['roi_labels'], self.dset[idx])\n",
    "        return data\n",
    "\n",
    "# for DatasetLoader\n",
    "def collate_fn(batch):\n",
    "    '''\n",
    "        Default collate_fn(): https://github.com/pytorch/pytorch/blob/1d53d0756668ce641e4f109200d9c65b003d05fa/torch/utils/data/_utils/collate.py#L43\n",
    "    '''\n",
    "    batch_data = {}\n",
    "    batch_data['img_name'] = []\n",
    "    batch_data['img_loc'] = []\n",
    "    batch_data['node_num'] = []\n",
    "    batch_data['roi_labels'] = []\n",
    "    batch_data['det_boxes'] = []\n",
    "    batch_data['edge_labels'] = []\n",
    "    batch_data['edge_num'] = []\n",
    "    batch_data['features'] = []\n",
    "    batch_data['spatial_feat'] = []\n",
    "    batch_data['word2vec'] = []\n",
    "    \n",
    "    for data in batch:\n",
    "        batch_data['img_name'].append(data['img_name'])\n",
    "        batch_data['img_loc'].append(data['img_loc'])\n",
    "        batch_data['node_num'].append(data['node_num'])\n",
    "        batch_data['roi_labels'].append(data['roi_labels'])\n",
    "        batch_data['det_boxes'].append(data['det_boxes'])\n",
    "        batch_data['edge_labels'].append(data['edge_labels'])\n",
    "        batch_data['edge_num'].append(data['edge_num'])\n",
    "        batch_data['features'].append(data['features'])\n",
    "        batch_data['spatial_feat'].append(data['spatial_feat'])\n",
    "        batch_data['word2vec'].append(data['word2vec'])\n",
    "        \n",
    "    batch_data['edge_labels'] = torch.FloatTensor(np.concatenate(batch_data['edge_labels'], axis=0))\n",
    "    batch_data['features'] = torch.FloatTensor(np.concatenate(batch_data['features'], axis=0))\n",
    "    batch_data['spatial_feat'] = torch.FloatTensor(np.concatenate(batch_data['spatial_feat'], axis=0))\n",
    "    batch_data['word2vec'] = torch.FloatTensor(np.concatenate(batch_data['word2vec'], axis=0))\n",
    "    \n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import torch as t\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plot\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "def vis_img(img, node_classes, bboxs,  det_action, score_thresh = 0.7):\n",
    "    \n",
    "    Drawer = ImageDraw.Draw(img)\n",
    "    line_width = 3\n",
    "    outline = '#FF0000'\n",
    "    font = ImageFont.truetype(font='/usr/share/fonts/truetype/freefont/FreeMono.ttf', size=25)\n",
    "    \n",
    "    im_w,im_h = img.size\n",
    "    node_num = len(node_classes)\n",
    "    edge_num = len(det_action)\n",
    "    tissue_num = len(np.where(node_classes == 1)[0])\n",
    "    \n",
    "    for node in range(node_num):\n",
    "        \n",
    "        r_color = random.choice(np.arange(256))\n",
    "        g_color = random.choice(np.arange(256))\n",
    "        b_color = random.choice(np.arange(256))\n",
    "        \n",
    "        text = data_const.instrument_classes[node_classes[node]]\n",
    "        h, w = font.getsize(text)\n",
    "        Drawer.rectangle(list(bboxs[node]), outline=outline, width=line_width)\n",
    "        Drawer.text(xy=(bboxs[node][0], bboxs[node][1]-w-1), text=text, font=font, fill=(r_color,g_color,b_color))\n",
    "  \n",
    "    edge_idx = 0\n",
    "    \n",
    "    for tissue in range(tissue_num):\n",
    "        for instrument in range(tissue+1, node_num):\n",
    "            \n",
    "            #action_idx = np.where(det_action[edge_idx] > score_thresh)[0]\n",
    "            action_idx = np.argmax(det_action[edge_idx])\n",
    "#             print('det_action', det_action[edge_idx])\n",
    "#             print('action_idx',action_idx)\n",
    "            \n",
    "            text = data_const.action_classes[action_idx]\n",
    "            r_color = random.choice(np.arange(256))\n",
    "            g_color = random.choice(np.arange(256))\n",
    "            b_color = random.choice(np.arange(256))\n",
    "        \n",
    "            x1,y1,x2,y2 = bboxs[tissue]\n",
    "            x1_,y1_,x2_,y2_ = bboxs[instrument]\n",
    "            \n",
    "            c0 = int(0.5*x1)+int(0.5*x2)\n",
    "            c0 = max(0,min(c0,im_w-1))\n",
    "            r0 = int(0.5*y1)+int(0.5*y2)\n",
    "            r0 = max(0,min(r0,im_h-1))\n",
    "            c1 = int(0.5*x1_)+int(0.5*x2_)\n",
    "            c1 = max(0,min(c1,im_w-1))\n",
    "            r1 = int(0.5*y1_)+int(0.5*y2_)\n",
    "            r1 = max(0,min(r1,im_h-1))\n",
    "            Drawer.line(((c0,r0),(c1,r1)), fill=(r_color,g_color,b_color), width=3)\n",
    "            Drawer.text(xy=(c1, r1), text=text, font=font, fill=(r_color,g_color,b_color))\n",
    "\n",
    "            edge_idx +=1\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import sklearn.metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def ece_eval(preds, targets, n_bins=10, bg_cls = 0):\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    confidences, predictions = np.max(preds,1), np.argmax(preds,1)\n",
    "    confidences, predictions = confidences[targets>bg_cls], predictions[targets>bg_cls]\n",
    "    accuracies = (predictions == targets[targets>bg_cls]) \n",
    "    Bm, acc, conf = np.zeros(n_bins), np.zeros(n_bins), np.zeros(n_bins)\n",
    "    ece = 0.0\n",
    "    bin_idx = 0\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = np.logical_and(confidences > bin_lower, confidences <= bin_upper)\n",
    "        #in_bin = in_bin[targets>backgound_class]\n",
    "        bin_size = np.sum(in_bin)\n",
    "        \n",
    "        Bm[bin_idx] = bin_size\n",
    "        if bin_size > 0:  \n",
    "            accuracy_in_bin = np.sum(accuracies[in_bin])\n",
    "            acc[bin_idx] = accuracy_in_bin / Bm[bin_idx]\n",
    "            confidence_in_bin = np.sum(confidences[in_bin])\n",
    "            conf[bin_idx] = confidence_in_bin / Bm[bin_idx]\n",
    "        bin_idx += 1\n",
    "        \n",
    "    ece_all = Bm * np.abs((acc - conf))/ Bm.sum()\n",
    "    ece = ece_all.sum() \n",
    "    return ece, acc, conf, Bm\n",
    "\n",
    "def get_sce(preds, targets, n_bins=10, **args):\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    \n",
    "    n_objects, n_classes = preds.shape\n",
    "    res = 0.0\n",
    "    for cur_class in range(n_classes):\n",
    "        for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "            cur_class_conf = preds[:, cur_class]\n",
    "            in_bin = np.logical_and(cur_class_conf > bin_lower, cur_class_conf <= bin_upper)\n",
    "\n",
    "            # cur_class_acc is ground truth probability of chosen class being the correct one inside the bin.\n",
    "            # NOT fraction of correct predictions in the bin\n",
    "            # because it is compared with predicted probability\n",
    "            bin_acc = (targets[in_bin] == cur_class)\n",
    "            \n",
    "            bin_conf = cur_class_conf[in_bin]\n",
    "\n",
    "            bin_size = np.sum(in_bin)\n",
    "            \n",
    "            if bin_size > 0:\n",
    "                avg_confidence_in_bin = np.mean(bin_conf)\n",
    "                avg_accuracy_in_bin = np.mean(bin_acc)\n",
    "                delta = np.abs(avg_confidence_in_bin - avg_accuracy_in_bin)\n",
    "#                 print(f'bin size {bin_size}, bin conf {avg_confidence_in_bin}, bin acc {avg_accuracy_in_bin}')\n",
    "                res += delta * bin_size / (n_objects * n_classes)\n",
    "    return res\n",
    "\n",
    "def get_tace(preds, targets, n_bins=15, threshold=1e-3, **args):\n",
    "    n_objects, n_classes = preds.shape\n",
    "    \n",
    "    res = 0.0\n",
    "    for cur_class in range(n_classes):\n",
    "        cur_class_conf = preds[:, cur_class]\n",
    "        \n",
    "        targets_sorted = targets[cur_class_conf.argsort()]\n",
    "        cur_class_conf_sorted = np.sort(cur_class_conf)\n",
    "        \n",
    "        targets_sorted = targets_sorted[cur_class_conf_sorted > threshold]\n",
    "        cur_class_conf_sorted = cur_class_conf_sorted[cur_class_conf_sorted > threshold]\n",
    "        \n",
    "        bin_size = len(cur_class_conf_sorted) // n_bins\n",
    "                \n",
    "        for bin_i in range(n_bins):\n",
    "            bin_start_ind = bin_i * bin_size\n",
    "            if bin_i < n_bins-1:\n",
    "                bin_end_ind = bin_start_ind + bin_size\n",
    "            else:\n",
    "                bin_end_ind = len(targets_sorted)\n",
    "                bin_size = bin_end_ind - bin_start_ind  # extend last bin until the end of prediction array\n",
    "            bin_acc = (targets_sorted[bin_start_ind : bin_end_ind] == cur_class)\n",
    "            bin_conf = cur_class_conf_sorted[bin_start_ind : bin_end_ind]\n",
    "            avg_confidence_in_bin = np.mean(bin_conf)\n",
    "            avg_accuracy_in_bin = np.mean(bin_acc)\n",
    "            delta = np.abs(avg_confidence_in_bin - avg_accuracy_in_bin)\n",
    "#             print(f'bin size {bin_size}, bin conf {avg_confidence_in_bin}, bin acc {avg_accuracy_in_bin}')\n",
    "            res += delta * bin_size / (n_objects * n_classes)\n",
    "            \n",
    "    return res\n",
    "\n",
    "def get_brier(preds, targets, **args):\n",
    "    one_hot_targets = np.zeros(preds.shape)\n",
    "    one_hot_targets[np.arange(len(targets)), targets] = 1.0\n",
    "    return np.mean(np.sum((preds - one_hot_targets) ** 2, axis=1))\n",
    "\n",
    "def nentr(p, base=None):\n",
    "    \"\"\"\n",
    "    Calculates entropy of p to the base b. If base is None, the natural logarithm is used.\n",
    "    :param p: batches of class label probability distributions (softmax output)\n",
    "    :param base: base b\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    eps = torch.tensor([1e-16], device=p.device)\n",
    "    if base:\n",
    "        base = torch.tensor([base], device=p.device, dtype=torch.float32)\n",
    "        return (p.mul(p.add(eps).log().div(base.log()))).sum(dim=1).abs()\n",
    "    else:\n",
    "        return (p.mul(p.add(eps).log())).sum(dim=1).abs()\n",
    "\n",
    "def uceloss(softmaxes, labels, n_bins=15):\n",
    "    d = softmaxes.device\n",
    "    bin_boundaries = torch.linspace(0, 1, n_bins + 1, device=d)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    _, predictions = torch.max(softmaxes, 1)\n",
    "    _, labels = torch.max(labels, 1)\n",
    "    errors = predictions.ne(labels)\n",
    "    uncertainties = nentr(softmaxes, base=softmaxes.size(1))\n",
    "    errors_in_bin_list = []\n",
    "    avg_entropy_in_bin_list = []\n",
    "\n",
    "    uce = torch.zeros(1)\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        # Calculate |uncert - err| in each bin\n",
    "        in_bin = uncertainties.gt(bin_lower.item()) * uncertainties.le(bin_upper.item())\n",
    "        prop_in_bin = in_bin.float().mean()  # |Bm| / n\n",
    "        if prop_in_bin.item() > 0.0:\n",
    "            errors_in_bin = errors[in_bin].float().mean()  # err()\n",
    "            avg_entropy_in_bin = uncertainties[in_bin].mean()  # uncert()\n",
    "            uce += torch.abs(avg_entropy_in_bin - errors_in_bin) * prop_in_bin\n",
    "\n",
    "            errors_in_bin_list.append(errors_in_bin)\n",
    "            avg_entropy_in_bin_list.append(avg_entropy_in_bin)\n",
    "\n",
    "    err_in_bin = torch.tensor(errors_in_bin_list, device=d)\n",
    "    avg_entropy_in_bin = torch.tensor(avg_entropy_in_bin_list, device=d)\n",
    "\n",
    "    return uce#, err_in_bin, avg_entropy_in_bin\n",
    "\n",
    "def compute_mean_avg_prec(y_true, y_score):\n",
    "    try:\n",
    "        avg_prec = sklearn.metrics.average_precision_score(y_true, y_score, average=None)\n",
    "        mean_avg_prec = np.nansum(avg_prec) / len(avg_prec)\n",
    "    except ValueError:\n",
    "        mean_avg_prec = 0\n",
    "\n",
    "    return mean_avg_prec\n",
    "\n",
    "def reliability_diagram_multi(conf_avg, acc_avg, rdname, legend=None, leg_idx=0, n_bins=10):\n",
    "    plt.clf()\n",
    "    plt.figure(2)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(np.arange(0, 1.1, 1/n_bins))\n",
    "    #plt.title(title)\n",
    "    plt.plot(conf_avg[acc_avg>0],acc_avg[acc_avg>0], marker='.', label = legend)\n",
    "    plt.legend()\n",
    "    plt.savefig('figures/reliability_diagram/'+rdname+'ece_rel_multi.png',dpi=300)\n",
    "\n",
    "def calibration_metrics(logits_all, labels_all, rdname, plot=False, model_name='graph_network'):\n",
    "    uce = uceloss( logits_all.cpu(), labels_all.cpu())\n",
    "    \n",
    "    logits = logits_all.detach().cpu().numpy()\n",
    "    labels = labels_all.detach().cpu().numpy()\n",
    "    map_value = compute_mean_avg_prec(labels, logits)\n",
    "    \n",
    "    labels = np.argmax(labels, axis=-1)\n",
    "    ece, acc, conf, Bm = ece_eval(logits, labels, bg_cls=-1)\n",
    "    sce = get_sce(logits, labels)\n",
    "    tace = get_tace(logits, labels)\n",
    "    brier = get_brier(logits, labels)\n",
    "    #print('%s:, ece:%0.4f, sce:%0.4f, tace:%0.4f, brier:%.4f, uce:%.4f' %(model_name, ece, sce, tace, brier, uce.item()) )\n",
    "    if plot: reliability_diagram_multi(conf, acc, rdname, legend=model_name)\n",
    "    return(map_value, ece, sce, tace, brier, uce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import utils.io as io\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def seed_everything(seed=27):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def evaluate(args, model, seq, device, dname, rdname, plot = False):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    \n",
    "    val_dataset = SurgicalSceneDataset(seq_set = seq['val_seq'], data_dir = seq['data_dir'], \\\n",
    "                            img_dir = seq['img_dir'], dset = seq['dset'], dataconst = data_const, \\\n",
    "                            feature_extractor = args.feature_extractor, reduce_size = False)\n",
    "    val_dataloader = DataLoader(dataset=val_dataset, batch_size=args.batch_size, shuffle= True, \\\n",
    "                            collate_fn=collate_fn)\n",
    "    \n",
    "    # model evaluate\n",
    "    model.eval()\n",
    "    \n",
    "    # criterion and scheduler\n",
    "    criterion = nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "    # each epoch has a training and validation step                   \n",
    "    edge_count = 0\n",
    "    total_acc = 0.0\n",
    "    total_loss = 0.0\n",
    "    logits_list = []\n",
    "    labels_list = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for data in val_dataloader:\n",
    "        train_data = data\n",
    "        img_name = train_data['img_name']\n",
    "        img_loc = train_data['img_loc']\n",
    "        node_num = train_data['node_num']\n",
    "        roi_labels = train_data['roi_labels']\n",
    "        det_boxes = train_data['det_boxes']\n",
    "        edge_labels = train_data['edge_labels']\n",
    "        edge_num = train_data['edge_num']\n",
    "        features = train_data['features']\n",
    "        spatial_feat = train_data['spatial_feat']\n",
    "        word2vec = train_data['word2vec']\n",
    "        features, spatial_feat, word2vec, edge_labels = features.to(device), spatial_feat.to(device), word2vec.to(device), edge_labels.to(device)    \n",
    "            \n",
    "        with torch.no_grad():\n",
    "            outputs = model(node_num, features, spatial_feat, word2vec, roi_labels, validation=True)\n",
    "            if args.use_t: outputs/args.t_scale\n",
    "            \n",
    "            logits_list.append(outputs)\n",
    "            labels_list.append(edge_labels)       \n",
    "            \n",
    "            # loss and accuracy\n",
    "            loss = criterion(outputs, edge_labels.float())\n",
    "            acc = np.sum(np.equal(np.argmax(outputs.cpu().data.numpy(), axis=-1), np.argmax(edge_labels.cpu().data.numpy(), axis=-1)))\n",
    "            \n",
    "        # accumulate loss and accuracy of the batch\n",
    "        total_loss += loss.item() * edge_labels.shape[0]\n",
    "        total_acc  += acc\n",
    "        edge_count += edge_labels.shape[0]\n",
    "    \n",
    "    logits_all = torch.cat(logits_list).cuda()\n",
    "    labels_all = torch.cat(labels_list).cuda()\n",
    "    \n",
    "    # calculate the loss and accuracy\n",
    "    total_acc = total_acc / edge_count\n",
    "    total_loss = total_loss / len(val_dataloader)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    logits_all = F.softmax(logits_all, dim=1)\n",
    "    map_value, ece, sce, tace, brier, uce = calibration_metrics(logits_all, labels_all, rdname, plot=plot, model_name='graph')\n",
    "    print('acc: %0.6f map: %0.6f loss: %0.6f, ece:%0.6f, sce:%0.6f, tace:%0.6f, brier:%.6f, uce:%.6f' %(total_acc, map_value, total_loss, ece, sce, tace, brier, uce.item()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.485557 map: 0.247673 loss: 14.004948, ece:0.182589, sce:0.039834, tace:0.040764, brier:0.724628, uce:0.196915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.495873 map: 0.269373 loss: 13.910110, ece:0.164012, sce:0.039617, tace:0.039186, brier:0.720225, uce:0.193668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.502751 map: 0.277975 loss: 13.905481, ece:0.170233, sce:0.039566, tace:0.038749, brier:0.720705, uce:0.196217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.513755 map: 0.279818 loss: 13.866458, ece:0.168548, sce:0.038988, tace:0.040074, brier:0.720936, uce:0.195378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.515131 map: 0.280902 loss: 13.852536, ece:0.169601, sce:0.039148, tace:0.039220, brier:0.719348, uce:0.190695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.523384 map: 0.283751 loss: 13.764285, ece:0.168208, sce:0.039178, tace:0.038381, brier:0.714713, uce:0.173640\n",
      "acc: 0.522696 map: 0.285436 loss: 13.734008, ece:0.164536, sce:0.037651, tace:0.037666, brier:0.709483, uce:0.179234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "arguments\n",
    "    Hyperparameters, file location, optimizer, network, data_processing\n",
    "'''\n",
    "ver = 'd2g_ecbs_t_resnet18_11_cbs_ts'\n",
    "f_e = 'resnet18_11_cbs_ts'\n",
    "\n",
    "class arguments():\n",
    "    def __init__(self):\n",
    "\n",
    "        self.batch_size = 32\n",
    "\n",
    "        # network\n",
    "        self.layers= 1\n",
    "        self.bn = False\n",
    "        self.drop_prob = 0.3\n",
    "        self.bias = True\n",
    "        self.multi_attn = False\n",
    "        self.diff_edge = False\n",
    "\n",
    "        # data_processing\n",
    "        self.sampler = 0\n",
    "        self.data_aug = False\n",
    "        self.feature_extractor = f_e\n",
    "        \n",
    "        # CBS\n",
    "        self.use_cbs = True\n",
    "        \n",
    "        # temperature_scaling\n",
    "        self.use_t = True\n",
    "        self.t_scale = 1.5\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    seed_everything()\n",
    "    args = arguments()\n",
    "    data_const = SurgicalSceneConstants()\n",
    "    \n",
    "    # val dataset\n",
    "    val_seq = [[1,5,16],[16,17,18,19,20,21,22]]\n",
    "    data_dir = ['datasets/instruments18/seq_', 'datasets/SGH_dataset_2020/']\n",
    "    img_dir = ['/left_frames/', '/resized_frames/']\n",
    "    dset = [0, 1]\n",
    "    seq = {'val_seq': val_seq, 'data_dir': data_dir, 'img_dir':img_dir, 'dset': dset}\n",
    "    \n",
    "    # model\n",
    "    model = AGRNN(bias=args.bias, bn=args.bn, dropout=args.drop_prob, multi_attn=args.multi_attn, layer=args.layers, diff_edge=args.diff_edge, use_cbs = args.use_cbs)\n",
    "    if args.use_cbs: model.grnn1.gnn.apply_h_h_edge.get_new_kernels(0)\n",
    "    \n",
    "    for i in [20,30,40,50,60,70,80]:\n",
    "        pretrain_model = 'checkpoints/'+ver+'/'+ver+'/'+'epoch_train/checkpoint_D2F'+str(i)+'_epoch.pth'\n",
    "        checkpoints = torch.load(pretrain_model)\n",
    "        model.load_state_dict(checkpoints['state_dict'])\n",
    "    \n",
    "        # use cpu or cuda\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "    \n",
    "        evaluate(args, model,seq, device, \"D12\", str(i))  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.523384 map: 0.283751 loss: 13.764285, ece:0.168208, sce:0.039178, tace:0.038381, brier:0.714713, uce:0.173640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "/usr/local/lib/python3.6/dist-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.522696 map: 0.285436 loss: 13.734008, ece:0.164536, sce:0.037651, tace:0.037666, brier:0.709483, uce:0.179234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    for i in [70,80]:\n",
    "        pretrain_model = 'checkpoints/'+ver+'/'+ver+'/'+'epoch_train/checkpoint_D2F'+str(i)+'_epoch.pth'\n",
    "        checkpoints = torch.load(pretrain_model)\n",
    "        model.load_state_dict(checkpoints['state_dict'])\n",
    "    \n",
    "        # use cpu or cuda\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "    \n",
    "        evaluate(args, model,seq, device, \"D12\", str(i), plot=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
