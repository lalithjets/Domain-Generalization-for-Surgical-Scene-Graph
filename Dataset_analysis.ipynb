{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================= MICCAI DATASET ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrument [[149.]\n",
      " [146.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [147.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]]\n",
      "action [[310.]\n",
      " [  1.]\n",
      " [  5.]\n",
      " [ 21.]\n",
      " [  0.]\n",
      " [ 94.]\n",
      " [ 11.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]]\n"
     ]
    }
   ],
   "source": [
    "#System\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "if sys.version_info[0] == 2: import xml.etree.cElementTree as ET\n",
    "else: import xml.etree.ElementTree as ET\n",
    "\n",
    "# input data and IO folder location\n",
    "mlist = [16]\n",
    "\n",
    "dir_root_gt = 'datasets/instruments18/seq_'\n",
    "xml_dir_list = []\n",
    "\n",
    "for i in mlist:\n",
    "    xml_dir_temp = dir_root_gt + str(i) + '/xml/'\n",
    "    seq_list_each = glob(xml_dir_temp + '/*.xml')\n",
    "    xml_dir_list = xml_dir_list + seq_list_each\n",
    "    \n",
    "# global variables\n",
    "INSTRUMENT_CLASSES = ('kidney', 'bipolar_forceps', 'prograsp_forceps', 'large_needle_driver',\n",
    "                      'monopolar_curved_scissors', 'ultrasound_probe', 'suction', 'clip_applier',\n",
    "                      'stapler', 'maryland_dissector', 'spatulated_monopolar_cautery')\n",
    "\n",
    "ACTION_CLASSES = ('Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation', 'Tool_Manipulation',\n",
    "                  'Cutting', 'Cauterization', 'Suction', 'Looping', 'Suturing', 'Clipping', \n",
    "                  'Staple', 'Ultrasound_Sensing')\n",
    "\n",
    "instrument_cls_freq = np.zeros((11,1))\n",
    "action_cls_freq = np.zeros((13,1))\n",
    "\n",
    "for index, _xml_dir in  enumerate(xml_dir_list):\n",
    "    _xml = ET.parse(_xml_dir).getroot()\n",
    "    c_flag = False\n",
    "    \n",
    "    for obj in _xml.iter('objects'):\n",
    "        # object name and interaction type\n",
    "        name = obj.find('name').text.strip()\n",
    "        interact = obj.find('interaction').text.strip()\n",
    "        instrument_cls_freq[int(INSTRUMENT_CLASSES.index(str(name)))] += 1\n",
    "        action_cls_freq[int(ACTION_CLASSES.index(str(interact)))] += 1\n",
    "    if c_flag: continue\n",
    "\n",
    "print('instrument', instrument_cls_freq)\n",
    "print('action', action_cls_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================= SGH DATASET ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrument [[10.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [10.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [10.]\n",
      " [10.]]\n",
      "action [[11.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [11.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "#System\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "if sys.version_info[0] == 2: import xml.etree.cElementTree as ET\n",
    "else: import xml.etree.ElementTree as ET\n",
    "\n",
    "# input data and IO folder location\n",
    "mlist = [1]\n",
    "\n",
    "dir_root_gt = 'datasets/SGH_dataset_2020/'\n",
    "xml_dir_list = []\n",
    "\n",
    "for i in mlist:\n",
    "    xml_dir_temp = dir_root_gt + str(i) + '/xml/'\n",
    "    seq_list_each = glob(xml_dir_temp + '/*.xml')\n",
    "    xml_dir_list = xml_dir_list + seq_list_each\n",
    "    \n",
    "# global variables\n",
    "INSTRUMENT_CLASSES = ('tissue', 'bipolar_forceps', 'prograsp_forceps', 'large_needle_driver',\n",
    "                      'monopolar_curved_scissors', 'ultrasound_probe', 'suction', 'clip_applier',\n",
    "                      'stapler', 'maryland_dissector', 'spatulated_monopolar_cautery')\n",
    "\n",
    "ACTION_CLASSES = ('Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation', 'Tool_Manipulation',\n",
    "                  'Cutting', 'Cauterization', 'Suction', 'Looping', 'Suturing', 'Clipping', \n",
    "                  'Staple', 'Ultrasound_Sensing')\n",
    "\n",
    "instrument_cls_freq = np.zeros((11,1))\n",
    "action_cls_freq = np.zeros((13,1))\n",
    "\n",
    "for index, _xml_dir in  enumerate(xml_dir_list):\n",
    "    _xml = ET.parse(_xml_dir).getroot()\n",
    "    c_flag = False\n",
    "    \n",
    "    for obj in _xml.iter('objects'):\n",
    "        # object name and interaction type\n",
    "        name = obj.find('name').text.strip()\n",
    "        interact = obj.find('interaction').text.strip()\n",
    "        instrument_cls_freq[int(INSTRUMENT_CLASSES.index(str(name)))] += 1\n",
    "        action_cls_freq[int(ACTION_CLASSES.index(str(interact)))] += 1\n",
    "    if c_flag: continue\n",
    "\n",
    "print('instrument', instrument_cls_freq)\n",
    "print('action', action_cls_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============== Classsification DATASET ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2223.]\n",
      " [2396.]\n",
      " [1960.]\n",
      " [1315.]\n",
      " [1862.]\n",
      " [ 610.]\n",
      " [ 442.]\n",
      " [  89.]\n",
      " [ 131.]\n",
      " [ 172.]\n",
      " [ 185.]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "filenames = glob.glob(\"datasets/classification_m17_18_sgh_20//*.png\")\n",
    "\n",
    "instrument_cls_freq = np.zeros((11,1))\n",
    "\n",
    "for idx, filename in enumerate(filenames):\n",
    "    filename_data = filename.split('_')\n",
    "    class_num = int(filename_data[-1].split('.')[0])\n",
    "    instrument_cls_freq[class_num] += 1\n",
    "\n",
    "print(instrument_cls_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:00, 6201.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrument [[13.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [13.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "action [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#System\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "if sys.version_info[0] == 2: import xml.etree.cElementTree as ET\n",
    "else: import xml.etree.ElementTree as ET\n",
    "\n",
    "# input data and IO folder location\n",
    "mlist = [3]\n",
    "\n",
    "dir_root_gt = 'datasets/YouTubeDataset/'\n",
    "xml_dir_list = []\n",
    "\n",
    "for i in mlist:\n",
    "    xml_dir_temp = dir_root_gt + str(i) + '/xml/'\n",
    "    seq_list_each = glob(xml_dir_temp + '/*.xml')\n",
    "    xml_dir_list = xml_dir_list + seq_list_each\n",
    "    \n",
    "# global variables\n",
    "INSTRUMENT_CLASSES = ('tissue', 'bipolar_forceps', 'prograsp_forceps', 'large_needle_driver',\n",
    "                      'monopolar_curved_scissors', 'ultrasound_probe', 'suction', 'clip_applier',\n",
    "                      'stapler', 'maryland_dissector', 'spatulated_monopolar_cautery')\n",
    "\n",
    "ACTION_CLASSES = ('Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation', 'Tool_Manipulation',\n",
    "                  'Cutting', 'Cauterization', 'Suction', 'Looping', 'Suturing', 'Clipping', \n",
    "                  'Staple', 'Ultrasound_Sensing')\n",
    "\n",
    "instrument_cls_freq = np.zeros((11,1))\n",
    "action_cls_freq = np.zeros((13,1))\n",
    "\n",
    "for index, _xml_dir in  tqdm(enumerate(xml_dir_list)):\n",
    "    _xml = ET.parse(_xml_dir).getroot()\n",
    "    c_flag = False\n",
    "    \n",
    "    for obj in _xml.iter('objects'):\n",
    "        # object name and interaction type\n",
    "        name = obj.find('name').text.strip()\n",
    "        #interact = obj.find('interaction').text.strip()\n",
    "        instrument_cls_freq[int(INSTRUMENT_CLASSES.index(str(name)))] += 1\n",
    "        #action_cls_freq[int(ACTION_CLASSES.index(str(interact)))] += 1\n",
    "    if c_flag: continue\n",
    "print('instrument', instrument_cls_freq)\n",
    "print('action', action_cls_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train and Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit5c4d4791651c4ebab0ddd51ba4f611a8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
